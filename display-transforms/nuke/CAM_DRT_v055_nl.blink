kernel DRT_CAM_Kernel : ImageComputationKernel<ePixelWise>
{
  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image
  Image<eWrite>                            dst; // the output image

param:
  // AP1 clamp
  bool AP1Clamp;

  // Primaries of the Input Image
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65
  // 3: Rec.2020-D65
  // 4: P3-D65
  // 5: P3-DCI
  int primariesIn;

  // Disable Degree of Adaptation
  // This is only effective if the limit primaries have a non-D65 white point
  // since the input conversion is assumed to be fully adapted
  // and the output conversion does not apply a CAT
  bool discountIlluminant_in;
  bool discountIlluminant_out;

  // Toggles for Hellwig 2022 specific params
  bool HK_mode_in;
  bool HK_mode_out;
  int  cc_et;

  // Reference Luminance in Cd/sqm
  float referenceLuminance; // TODO: reference only for tonescale curve
                            // can it be factored in or removed (is it duplicated)

  // Viewing Conditions (for output)
  // 0: Dark
  // 1: Dim
  // 2: Average
  int inputViewingConditions;
  int outputViewingConditions;

  // Toggle Tone Mapping
  bool applyTonecurve;

  // Target Peak Luminance
  float peakLuminance;

  // Toggle chroma compression
  bool applyChromaCompression;

  // Chroma compression params
  float chroma_compress;
  float chroma_compress_fact;
  float chroma_expand;
  float chroma_expand_fact;
  float chroma_expand_thr;
  int   ccReach;
  // xy coordinates for chroma compression gamut
  float2 crxy;
  float2 cgxy;
  float2 cbxy;
  float2 cwxy;

  //
  // Gamut Mapping Parameters
  //

  // Primaries of the Target Gamut
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65 # now just Rec.709
  // 3: Rec.2020-D65 # now just Rec.2020
  // 4: P3-D65 # now just P3
  // 5: P3-DCI # no longer included
  int primariesLimit;

  // White point of the limiting gamut
  // effectively the "creative white"
  // 0: ACES white
  // 1: D65
  // Could add others, or user white point
  int whiteLimit;

  // Toggle Gamut Compression
  bool applyGamutCompression;

  // the 1D LUT used for quickly finding the approximate limiting gamut cusp JMh coordinates
  // the samples are spaced by HSV hue increments of the limiting RGB gamut
  // so to find the correct entry for a given CAM hue (h) value
  // one must search the table entries for the matching entry.z component
  int gamutCuspTableSize;

  // Blend Between Compressing towards
  // Target Gamut Cusp Luminance (0.0)
  // and Mid Luminance (1.0)
  float cuspMidBlend;

  // Focus distance of the compression focal point from the achromatic axis
  float focusDistance;
  float focusAdjustGain;
  float focusGainBlend;
  bool  disableFocusGain;
  bool  disableFocusDistScaling;
  float focusDistScaling;

  // Gamut Compression Fuction Parameters
  // Threshold / min Limit / max Limit / Power
  float4 compressionFuncParams;

  bool  disableUpperHullGamma;
  bool  disableLowerHullGamma;
  float lowerHullGamma;
  float upperHullGamma;

  // How much the edges of the target RGB cube are smoothed when finding the gamut boundary
  // in order to reduce visible contours at the gamut cusps
  float smoothCusps;
  float smoothJ; // Scaling factor for cusp J
  float smoothM; // Scaling factor for cusp M

  //
  // Output Parameters
  //

  // Primaries of the Output Image
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65
  // 3: Rec.2020-D65
  // 4: P3-D65
  // 5: P3-DCI
  int primariesOut;

  // Clamp output values to 0.0 - 1.0
  bool  fitWhite;
  bool  clampOutput;
  bool  softclampOutput;
  float clamp_thr;
  float clamp_dist;

  //
  // Extra Parameters
  //

  // Toggle Inverse Transform
  bool invert;
  // Diagnostic path modes
  int diagnosticMode;

  // DanieleEvoCurve (ACES2 candidate) parameters
  float mmScaleFactor;     // TODO: can we factor this into something? Should be renamed if not.
  float daniele_n;         // peak white
  float daniele_n_r;       // Normalized white in nits (what 1.0 should be)
  float daniele_g;         // surround / contrast
  float daniele_c;         // scene-referred grey
  float daniele_c_d;       // display-referred grey (in nits)
  float daniele_w_g;       // grey change between different peak luminance
  float daniele_t_1;       // shadow toe, flare/glare compensation - how ever you want to call it
  float daniele_r_hit_min; // Scene-referred value "hitting the roof" at 100 nits
  float daniele_r_hit_max; // Scene-referred value "hitting the roof" at 10,000 nits

  // Hellwig 2022 CAM params
  // the kernel parameters

  // 0 = Stock CAT16
  // 1 = Thomas's custom primaries
  // 2 = live from params below
  int catDataSelection; // original vs modified CAT16 matrix
  // xy coordinates for custom CAT matrix
  float2 rxy;
  float2 gxy;
  float2 bxy;
  float2 wxy;
  float  ra;
  float  ba;

  // Input vars
  float3 XYZ_w;
  float  XYZ_w_scaler;
  float  L_A;
  float  Y_b;
  float3 L_B;
  float3 userSurround;
  bool   discount_illuminant;
  // Output vars
  float L_A_out;
  float Y_b_out;

  int   nonlinearity_mode;
  float ql;
  float qu;
  float qz;

local:

  float3x3 CAT_CAT16;
  float3x3 CAT_CAT16_INVERSE;
  float3x3 panlrcm;

  float daniele_r_hit;
  float daniele_m_0;
  float daniele_m_1;
  float daniele_u;
  float daniele_m;
  float daniele_w_i;
  float daniele_c_t;
  float daniele_g_ip;
  float daniele_g_ipp2;
  float daniele_w_2;
  float daniele_s_2;
  float daniele_u_2;
  float daniele_m_2;

  // Chroma compression pre-calculated constants
  float compr;   // Compression
  float sat;     // Saturation
  float sat_thr; // Threshold to start expanding saturation

  // Gamut mapper constants
  float focusDist; // FocusDistance for projection

  // using the float3x3 type to store the array of 6 coefficients
  // because Blink does not support generic array assignments

  // matrix vars
  float3x3 identity_matrix;

  float3x3 XYZ_to_RGB_limit;
  float3x3 RGB_to_XYZ_input;
  float3x3 RGB_to_XYZ_limit;
  float3x3 RGB_to_XYZ_output;

  float3x3 AP1_to_XYZ;
  float3x3 XYZ_to_AP1;

  // white points
  float3 inWhite;
  float3 limitWhite;

  // the maximum lightness value of the limiting gamut
  float limitJmax;

  // Middle gray J
  float midJ;

  // Hellwig model's gamma (1 / cz)
  float  model_gamma;
  float  clamped_smoothness;
  float2 smooth_cusp_scale;


  // 361 - Adds an extra entry to wrap the hues without branching
  // Non-uniform in h
  float3 limitingGamutCuspTable[361];
  float3 cgamutCuspTable[361];
  // Uniform h
  float3 reachGamutCuspTable[361];
  float2 gamutGammas[361];

  // Hellwig 2022 constants
  float  F_L[2];
  float  z[2];
  float3 D_RGB[2];
  float  A_w[2];
  float  y_to_j_A_w[2];
  float3 achromatic_weights;
  float3 a_weights;
  float3 b_weights;

  // Nonlinearity 'constants'
  float nl_gamma;
  float nl_normalise;
  float nl_scale;
  float nl_offset;
  float nl_d_scale;

  // Per "stage" precomputed nonlinearity function variables
  float nl_Fl_scaled[2];
  float nl_derivative_scale[2];
  float nl_fql[2];
  float nl_fqu[2];
  float nl_lower_slope[2];
  float nl_upper_slope[2];
  float nl_a2[2];
  float nl_a1[2];
  float nl_a0[2];
  float nl_b_[2];
  float nl_average_roots[2];

  float fitWhiteScale;

  void define()
  {
    defineParam(chroma_compress_fact, "Chroma Compress Factor", 5.0f);
    defineParam(chroma_expand_fact, "Chroma Expansion Factor", 0.78f);
    defineParam(smoothJ, "Smoothing factor cusp J", 0.055f);
    defineParam(smoothM, "Smoothing factor cust M", 0.183f);

    defineParam(nonlinearity_mode, "Non-linearity Mode", 0);
    defineParam(ql, "Non-linearity Lower Break", 0.26f);
    defineParam(qu, "Non-linearity Upper Break", 150.0f);
    defineParam(qz, "Non-linearity intersection", 0.0f);
  }

  // Functions used in ACES 2.0 candidate CAM DRT

  // multiplies a 3D vector with a 3x3 matrix
  inline float3 vector_dot(const float3x3& m, const float3 v)
  {
    float3 r;
    for (int c = 0; c < 3; c++)
    {
      r[c] = m[c][0] * v.x + m[c][1] * v.y + m[c][2] * v.z;
    }

    return r;
  }

  // linear interpolation between two values a & b with the bias t
  inline float lerp(float a, float b, float t)
  {
    return a + t * (b - a);
  }
  inline float2 lerp(float2 a, float2 b, float t)
  {
    return a + t * (b - a);
  }
  inline float3 lerp(float3 a, float3 b, float t)
  {
    return a + t * (b - a);
  }
  inline float4 lerp(float4 a, float4 b, float t)
  {
    return a + t * (b - a);
  }

  inline float3 float3pow(float3 base, float exponent)
  {
    return float3(pow(base.x, exponent), pow(base.y, exponent), pow(base.z, exponent));
  }

  float degree_of_adaptation(float F, float _L_A)
  {
    float D = F * (1.0 - (1.0 / 3.6) * exp((-_L_A - 42.0f) / 92.0f));

    return D;
  }

  // convert radians to degrees
  inline float degrees(float radians)
  {
    return radians * 180.0f / PI;
  }

  // convert degrees to radians
  inline float radians(float degrees)
  {
    return degrees / 180.0f * PI;
  }

  // "PowerP" compression function (also used in the ACES Reference Gamut Compression transform)
  // values of v above  'threshold' are compressed by a 'power' function
  // so that an input value of 'limit' results in an output of 1.0
  float compressPowerP(float v, float threshold, float limit, float power, int inverse)
  {
    float s = (limit - threshold) / pow(pow((1.0f - threshold) / (limit - threshold), -power) - 1.0f, 1.0f / power);

    float vCompressed;

    if (inverse)
    {
      vCompressed = (v < threshold || limit < 1.0001f || v > threshold + s)
        ? v
        : threshold + s * pow(-(pow((v - threshold) / s, power) / (pow((v - threshold) / s, power) - 1.0f)), 1.0f / power);
    }
    else
    {
      vCompressed = (v < threshold || limit < 1.0001f)
        ? v
        : threshold + s * ((v - threshold) / s) / (pow(1.0f + pow((v - threshold) / s, power), 1.0f / power));
    }

    return vCompressed;
  }

  float3 compress_aces(float3 rgb, float3 c, float3 m, float3 y, int invert)
  {
    const float ach  = max(rgb.x, max(rgb.y, rgb.z));
    const float fach = fabs(ach);

    float3 d = 0.0f;
    if (ach)
    {
      d = (ach - rgb) / fach;
    }

    rgb.x = compressPowerP(d.x, c.x, c.y, c.z, invert);
    rgb.y = compressPowerP(d.y, m.x, m.y, m.z, invert);
    rgb.z = compressPowerP(d.z, y.x, y.y, y.z, invert);

    rgb = ach - rgb * fach;

    return rgb;
  }

  // Hellwig L, Stolitzka D,Fairchild MD.
  // Extending CIECAM02 and CAM16 for the Helmholtz–Kohlrausch effect.
  // Color Res Appl. 2022;1-9. doi:10.1002/col.22793
  float hue_angle_dependency_Hellwig2022(float hr)
  {
    return -0.160 * cos(hr) + 0.132 * cos(2 * hr) - 0.405 * sin(hr) + 0.080 * sin(2 * hr) + 0.792;
  }

  float3x3 RGBPrimsToXYZMatrix(float2 rxy, float2 gxy, float2 bxy, float2 wxy, float Y, bool direction)
  {
    // # given r g b chromaticities and whitepoint, convert RGB colors to XYZ
    // # based on CtlColorSpace.cpp from the CTL source code : 77
    // # param: xy - dict of chromaticity xy coordinates: rxy: float2(x, y) etc
    // # param: Y - luminance of "white" - defaults to 1.0
    // # param: inverse - calculate XYZ to RGB instead

    float2 r = rxy;
    float2 g = gxy;
    float2 b = bxy;
    float2 w = wxy;

    float X = w.x * Y / w.y;
    float Z = (1 - w.x - w.y) * Y / w.y;

    // # Scale factors for matrix rows
    float d = r.x * (b.y - g.y) + b.x * (g.y - r.y) + g.x * (r.y - b.y);

    // clang-format off
    float Sr =    (X * (b.y - g.y) -      \
            g.x * (Y * (b.y - 1.0f) +  \
            b.y * (X + Z)) +       \
            b.x * (Y * (g.y - 1.0f) + \
            g.y * (X + Z))) / d ;

    float Sg =    (X * (r.y - b.y) +      \
            r.x * (Y * (b.y - 1.0f) +  \
            b.y * (X + Z)) -        \
            b.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    float Sb =    (X * (g.y - r.y) -      \
            r.x * (Y * (g.y - 1.0f) +  \
            g.y * (X + Z)) +        \
            g.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    // # Assemble the matrix
    float Mdata[] =
    {
      Sr * r.x, Sg * g.x, Sb * b.x,
      Sr * r.y, Sg * g.y, Sb * b.y,
      Sr * (1.0f - r.x - r.y), Sg * (1.0f - g.x - g.y), Sb * (1.0f - b.x - b.y),
    };
    // clang-format on

    float3x3 newMatrix;
    newMatrix.setArray(Mdata);

    // return forward or inverse matrix
    if (direction == 0)
    {
      return newMatrix;
    }
    else if (direction == 1)
    {
      // create inverse matrix
      float3x3 newMatrixInverse = newMatrix.invert();
      return newMatrixInverse;
    }
  }

  float3 post_adaptation_non_linear_response_compression_forward_original(float3 RGB, int stage)
  {
    const float3 F_L_RGB = float3pow(F_L[stage] / 100.0f * fabs(RGB), 0.42f);
    const float3 RGB_c   = (400.0f * sign(RGB) * F_L_RGB) / (27.13f + F_L_RGB);
    return RGB_c;
  }

  float post_adaptation_non_linear_response_compression_forward_derivative_wheatley(float corresponding, int stage)
  {
    const float val   = fabs(corresponding);
    const float temp  = nl_derivative_scale[stage] * pow(nl_Fl_scaled[stage] * val, nl_gamma - 1.0f);
    const float temp1 = nl_offset + pow(nl_Fl_scaled[stage] * val, nl_gamma);
    return sign(corresponding) * temp / (temp1 * temp1);
  }

  float post_adaptation_non_linear_response_compression_forward_original_f(float corresponding, int stage)
  {
    const float q      = fabs(corresponding);
    const float sign_c = sign(corresponding);
    const float temp   = pow(nl_Fl_scaled[stage] * q, nl_gamma);
    return sign_c * (nl_scale * (temp / (temp + nl_offset)));
  }

  float post_adaptation_non_linear_response_compression_forward_wheatley_f(float corresponding, int stage)
  {
    const float q      = fabs(corresponding);
    const float sign_c = sign(corresponding);
    if (q > qu)
    {
      return sign_c * (nl_fqu[stage] + nl_upper_slope[stage] * (q - qu));
    }
    if (q < ql)
    {
      return sign_c * (nl_a2[stage] * q * q + nl_a1[stage] * q + nl_a0[stage]);
    }
    const float temp = pow(nl_Fl_scaled[stage] * q, nl_gamma);
    return sign_c * (nl_scale * (temp / (temp + nl_offset)));
  }

  float3 post_adaptation_non_linear_response_compression_forward_wheatley(float3 corresponding, int stage)
  {
    float3 non_linear;
    non_linear.x = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.x, stage);
    non_linear.y = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.y, stage);
    non_linear.z = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.z, stage);
    return non_linear;
  }

  inline float3 post_adaptation_non_linear_response_compression_forward(float3 RGB, int stage)
  {
    if (nonlinearity_mode == 1)
      return post_adaptation_non_linear_response_compression_forward_wheatley(RGB, stage);
    return post_adaptation_non_linear_response_compression_forward_original(RGB, stage);
  }

  float3 post_adaptation_non_linear_response_compression_inverse_original(float3 RGB, int stage)
  {
    const float3 absRGB = fabs(RGB);
    const float3 RGB_p  = sign(RGB) * 100.0f / F_L[stage] * float3pow((27.13f * absRGB) / (400.0f - absRGB), 1.0f / 0.42f);
    return RGB_p;
  }

  float post_adaptation_non_linear_response_compression_inverse_wheatley_f(float nl, int stage)
  {
    if (nl >= nl_fqu[stage])
    {
      return (nl - nl_fqu[stage]) / nl_upper_slope[stage] + qu;
    }
    if (nl <= nl_fql[stage])
    {
      // Quadratic solve
      const float c_ = nl / nl_a2[stage];        // TODO: no + a0
      const float u  = sqrt(nl_average_roots[stage] * nl_average_roots[stage] + c_);
      return float(nl_average_roots[stage] - u); // (average_roots < u) ? average_roots + u : ... always take this root
    }

    const float temp = (nl_offset * nl) / (nl_scale - nl);
    return pow(temp, 1.0 / nl_gamma) / nl_Fl_scaled[stage];
  }

  float3 post_adaptation_non_linear_response_compression_inverse_wheatley(float3 nonlinear, int stage)
  {
    const float3 nl     = fabs(nonlinear);
    const float3 sign_c = sign(nonlinear);
    float3       linear;
    linear.x = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.x, stage);
    linear.y = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.y, stage);
    linear.z = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.z, stage);
    return sign_c * linear;
  }

  inline float3 post_adaptation_non_linear_response_compression_inverse(float3 RGB, int stage)
  {
    if (nonlinearity_mode == 1)
      return post_adaptation_non_linear_response_compression_inverse_wheatley(RGB, stage);
    return post_adaptation_non_linear_response_compression_inverse_original(RGB, stage);
  }


  // convert HSV cylindrical projection values to RGB
  float3 HSV_to_RGB(float3 HSV)
  {
    float C = HSV.z * HSV.y;
    float X = C * (1.0f - fabs(fmod(HSV.x * 6.0f, 2.0f) - 1.0f));
    float m = HSV.z - C;

    float3 RGB;
    RGB.x = (HSV.x < 1.0f / 6.0f     ? C
               : HSV.x < 2.0f / 6.0f ? X
               : HSV.x < 3.0f / 6.0f ? 0.0f
               : HSV.x < 4.0f / 6.0f ? 0.0f
               : HSV.x < 5.0f / 6.0f ? X
                                     : C)
      + m;
    RGB.y = (HSV.x < 1.0f / 6.0f     ? X
               : HSV.x < 2.0f / 6.0f ? C
               : HSV.x < 3.0f / 6.0f ? C
               : HSV.x < 4.0f / 6.0f ? X
               : HSV.x < 5.0f / 6.0f ? 0.0f
                                     : 0.0f)
      + m;
    RGB.z = (HSV.x < 1.0f / 6.0f     ? 0.0f
               : HSV.x < 2.0f / 6.0f ? 0.0f
               : HSV.x < 3.0f / 6.0f ? X
               : HSV.x < 4.0f / 6.0f ? C
               : HSV.x < 5.0f / 6.0f ? C
                                     : X)
      + m;
    return RGB;
  }

  // convert RGB to HSV cylindrical projection values
  float3 RGB_to_HSV(float3 RGB)
  {
    float cmax  = max(RGB.x, max(RGB.y, RGB.z));
    float cmin  = min(RGB.x, min(RGB.y, RGB.z));
    float delta = cmax - cmin;

    float3 HSV;
    HSV.x = delta == 0.0f ? 0.0f
      : cmax == RGB.x     ? (fmod((RGB.y - RGB.z) / delta + 6.0f, 6.0f)) / 6.0f
      : cmax == RGB.y     ? (((RGB.z - RGB.x) / delta + 2.0f) / 6.0f)
                          : (((RGB.x - RGB.y) / delta + 4.0f) / 6.0f);
    HSV.y = cmax == 0.0f ? 0.0f : delta / cmax;
    HSV.z = cmax;
    return HSV;
  }

  // Smooth minimum of a and b
  float smin(float a, float b, float s)
  {
    float h = max(s - fabs(a - b), 0.0) / s;
    return min(a, b) - h * h * h * s * (1.0f / 6.0f);
  }

  // reimplemented from https://github.com/nick-shaw/aces-ot-vwg-experiments/blob/master/python/intersection_approx.py
  float solve_J_intersect(float2 JM, float focusJ, float maxJ, float slope_gain)
  {
    float a = JM.y / (focusJ * slope_gain);
    float b;
    float c;

    if (JM.x < focusJ)
    {
      b = 1.0f - JM.y / slope_gain;
      c = -JM.x;
    }
    else
    {
      b = -(1.0f + JM.y / slope_gain + maxJ * JM.y / (focusJ * slope_gain));
      c = maxJ * JM.y / slope_gain + JM.x;
    }

    const float root = sqrt(b * b - 4.0f * a * c);

    if (JM.x < focusJ)
    {
      return 2.0f * c / (-b - root);
    }
    else
    {
      return 2.0f * c / (-b + root);
    }
  }

  float3 viewingConditionsToSurround(int condition)
  {
    float3 newSurround;
    // hack to turn incoming int value into surround coeffs
    if (condition == 0)
    {
      // "Dark": InductionFactors_CIECAM02(0.8, 0.525, 0.8),
      newSurround = float3(0.8, 0.525, 0.8);
    }
    else if (condition == 1)
    {
      // "Dim": InductionFactors_CIECAM02(0.9, 0.59, 0.9),
      newSurround = float3(0.9, 0.59, 0.9);
    }
    else if (condition == 2)
    {
      // "Average": InductionFactors_CIECAM02(1, 0.69, 1),
      newSurround = float3(1.0, 0.69, 1.0);
    }
    else if (condition == 3)
    {
      // Pull from external input
      newSurround = userSurround;
    }
    return newSurround;
  }

  // convert XYZ tristimulus values to the CAM J (lightness), M (colorfulness) and h (hue) correlates
  // needs XYZ tristimulus values for the reference white and the viewing conditions as parameters
  inline float3 XYZ_to_JMh(float3 XYZ, int conditions, bool HK_mode, int stage)
  {
    return XYZ_to_Hellwig2022_JMh(XYZ, viewingConditionsToSurround(conditions), HK_mode, stage);
  }

  // convert the CAM J (lightness), M (colorfulness) and h (hue) correlates to XYZ tristimulus values
  // needs XYZ tristimulus values for the reference white and the viewing conditions as parameters
  inline float3 JMh_to_XYZ(float3 JMh, int conditions, bool HK_mode, int stage)
  {
    return Hellwig2022_JMh_to_XYZ(JMh, viewingConditionsToSurround(conditions), HK_mode, stage);
  }

  // convert CAM J (lightness), M (colorfulness) and h (hue) correlates to  RGB values in the output colorspace
  float3 XYZ_to_output_RGB(float3 luminanceXYZ)
  {
    // First matrix to limiting gamut for clamping
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_limit, luminanceXYZ); // TODO combine into one, be careful with gamma finding
    luminanceRGB *= fitWhiteScale;

    if (softclampOutput)
    {
      // Soft clamp by compressing negative display linear values
      float3 compr = float3(clamp_thr, clamp_dist, 1.2f);
      luminanceRGB = compress_aces(luminanceRGB, compr, compr, compr, 0);
    }

    if (clampOutput)
    {
      // Clamp to between zero and peak luminance
      luminanceRGB = clamp(luminanceRGB, 0.0f, peakLuminance);
    }

    // Matrix to output (encoding) gamut (eventually concatenate to a single matrix)
    luminanceRGB = vector_dot(RGB_to_XYZ_limit, luminanceRGB);

    return luminanceRGB;
  }

  // convert linear RGB values with the given primaries to CAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 RGB_to_JMh(const float3 RGB, const float3x3& matrix)
  {
    const float3 luminanceRGB = RGB * peakLuminance;
    const float3 XYZ          = vector_dot(matrix, luminanceRGB);
    const float3 JMh          = XYZ_to_JMh(XYZ, outputViewingConditions, HK_mode_out, 1); // TODO
    return JMh;
  }

  // convert CAM J (lightness), M (colorfulness) and h (hue) correlates to linear RGB values with the given primaries
  float3 JMh_to_RGB(float3 JMh, const float3x3& matrix)
  {
    float3 luminanceXYZ = JMh_to_XYZ(JMh, outputViewingConditions, HK_mode_out, 1);// TODO
    float3 luminanceRGB = vector_dot(matrix, luminanceXYZ);
    float3 RGB          = luminanceRGB / peakLuminance;
    return RGB;
  }

  // XYZ to Hellwig2020 JMh
  //
  //     XYZ
  //         *CIE XYZ* tristimulus values of test sample / stimulus.
  //     XYZ_w
  //         *CIE XYZ* tristimulus values of reference white.
  //     L_A
  //         Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`, (often taken
  //         to be 20% of the luminance of a white object in the scene).
  //     Y_b
  //         Luminous factor of background :math:`Y_b` such as
  //         :math:`Y_b = 100 x L_b / L_w` where :math:`L_w` is the luminance of the
  //         light source and :math:`L_b` is the luminance of the background. For
  //         viewing images, :math:`Y_b` can be the average :math:`Y` value for the
  //         pixels in the entire image, or frequently, a :math:`Y` value of 20,
  //         approximate an :math:`L^*` of 50 is used.
  //     surround
  //         Surround viewing conditions induction factors.
  //         Truth value indicating if the illuminant should be discounted.
  //     discount_illuminant
  //
  // NOTE: Following modifications have been made to stock Hellwig2022 model for this DRT:
  //
  // - Custom primaries
  //
  float3 XYZ_to_Hellwig2022_JMh(float3 XYZ, float3 surround, bool HK_mode, int stage)
  {
    // # Step 1
    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
    float3 RGB = vector_dot(CAT_CAT16, XYZ);

    // # Step 2
    float3 RGB_c = D_RGB[stage] * RGB;

    // # Step 3
    // # Applying forward post-adaptation non-linear response compression.

    float3 RGB_a = post_adaptation_non_linear_response_compression_forward(RGB_c, stage);

    // # Step 6 and Step 4
    // # Computing achromatic responses for the stimulus.
    // # Converting to preliminary cartesian coordinates.
    // basically a 3x3 matrix

    const float A = dot(achromatic_weights, RGB_a);
    const float a = dot(a_weights, RGB_a);
    const float b = dot(b_weights, RGB_a);

    // # Computing the *hue* angle :math:`h`.
    const float hr = atan2(b, a);
    const float h  = wrap_to_360(degrees(hr));

    // # Step 7
    // # Computing the correlate of *Lightness* :math:`J`.
    float J = 100.0f * pow(A / A_w[stage], surround.y * z[stage]);

    // # Step 8
    // # Computing the correlate of *brightness* :math:`Q`.
    // float Q = (2.0f / float(surround.y)) * (J / 100.0f) * A_w[stage];

    // # Step 9
    // # Computing the correlate of *colourfulness* :math:`M`.
    const float et = eccentricity_factor(hr);
    float       M  = 43.0f * surround.z * et * sqrt(a * a + b * b);

    // # Computing the correlate of *saturation* :math:`s`.
    // float s = 100.0f * div(M, Q); // possible div by 0

    if (HK_mode)
    {
      // # Computing the correlate of *chroma* :math:`C`.
      const float C = 35.0f * M / A_w[stage];
      // # *Helmholtz–Kohlrausch* Effect Extension.
      J = sqrt(J * J + 66.0f * C); //J + hue_angle_dependency_Hellwig2022(hr) * pow(C, 0.587f); // TODO: Luke's PhD has updated HK calculation
      // float Q_HK = (2.0f / surround.y) * (J / 100.0f) * A_w[stage];
    }

    if (J == 0.0f)
      M = 0.0f;
    return {J, M, h};
  }

  float3 Hellwig2022_JMh_to_XYZ(float3 JMh, float3 surround, bool HK_mode, int stage)
  {
    float       J  = JMh.x;
    const float M  = JMh.y;
    const float hr = radians(JMh.z);

    // # *Helmholtz–Kohlrausch* Effect Extension.
    if (HK_mode)
    {
      const float C = (M * 35.0f) / A_w[stage];
      J             = sqrt(J * J - 66.0f * C); //J - hue_angle_dependency_Hellwig2022(hr) * pow(C, 0.587f);
    }

    // # Computing achromatic response :math:`A` for the stimulus.
    const float A = A_w[stage] * pow(J / 100.0f, 1.0f / (surround.y * z[stage]));

    // # Computing *P_p_1* to *P_p_2*.
    const float et    = eccentricity_factor(hr);
    const float P_p_1 = 43.0f * et * surround.z;
    const float P_p_2 = A;

    // # Step 3
    // # Computing opponent colour dimensions :math:`a` and :math:`b`.
    const float gamma = M / P_p_1;
    const float a     = gamma * cos(hr);
    const float b     = gamma * sin(hr);

    // # Step 4
    // # Applying post-adaptation non-linear response compression matrix.
    const float3 RGB_a = vector_dot(panlrcm, float3(P_p_2, a, b));

    // # Step 5
    // # Applying inverse post-adaptation non-linear response compression.
    const float3 RGB_c = post_adaptation_non_linear_response_compression_inverse(RGB_a, stage);

    // # Step 6
    const float3 RGB = RGB_c / D_RGB[stage];

    // # Step 7
    const float3 XYZ = vector_dot(CAT_CAT16_INVERSE, RGB);

    return XYZ;
  }

  // retrieve the JM coordinates of the limiting gamut cusp at the hue slice 'h'
  // cusps are very expensive to compute
  // and the DRT is only using them for lightness mapping
  // which does not require a high degree of accuracy
  // so instead we use a pre-computed table of cusp points
  // sampled at 1 degree hue intervals of the the RGB target gamut
  // and lerp between them to get the approximate J & M values

  inline int midpoint(int low, int high)
  {
    return int((high + low) / 2); // Integer division
  }

  float2 limitingCuspFromTable(float wrapped_hue)
  {
    float3 lo;
    float3 hi;
    if (wrapped_hue <= limitingGamutCuspTable[0].z)
    {
      lo   = limitingGamutCuspTable[gamutCuspTableSize - 1];
      lo.z = lo.z - 360.0f;
      hi   = limitingGamutCuspTable[0];
    }
    else
    {
      int low_i  = 0;
      int high_i = gamutCuspTableSize; // Allowed as we have extra entry in the table
      int i      = hue_position_in_uniform_table(wrapped_hue, gamutCuspTableSize);

      while (low_i + 1 < high_i)
      {
        if (wrapped_hue > limitingGamutCuspTable[i].z)
        {
          low_i = i;
        }
        else
        {
          high_i = i;
        }
        i = midpoint(low_i, high_i);
      }
      lo = limitingGamutCuspTable[high_i - 1];
      hi = limitingGamutCuspTable[high_i];
    }

    float t = (wrapped_hue - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ, cuspM);
  }

  float2 ccuspFromTable(float wrapped_hue)
  {
    float3 lo;
    float3 hi;

    if (wrapped_hue <= cgamutCuspTable[0].z)
    {
      lo   = cgamutCuspTable[gamutCuspTableSize - 1];
      lo.z = lo.z - 360.0f;
      hi   = cgamutCuspTable[0];
    }
    else
    {
      int low_i  = 0;
      int high_i = gamutCuspTableSize; // Allowed as we have extra entry in the table
      int i      = hue_position_in_uniform_table(wrapped_hue, gamutCuspTableSize);

      while (low_i + 1 < high_i)
      {
        if (wrapped_hue > cgamutCuspTable[i].z)
        {
          low_i = i;
        }
        else
        {
          high_i = i;
        }
        i = midpoint(low_i, high_i);
      }
      lo = cgamutCuspTable[high_i - 1];
      hi = cgamutCuspTable[high_i];
    }

    float t = (wrapped_hue - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ, cuspM);
  }

  inline float wrap_to_360(float hue)
  {
    float y = fmod(hue, 360.0f);
    if (y < 0.0)
    {
      y = y + 360.0f;
    }
    return y;
  }

  inline int hue_position_in_uniform_table(float wrapped_hue, int table_size)
  {
    return int(wrapped_hue / 360.0f * table_size);
  }

  inline float base_hue_for_position(int i_lo, int table_size)
  {
    return float(i_lo) * 360.0f / float(table_size);
  }

  float cReachFromTable(float wrapped_hue)
  {
    const int i_lo = hue_position_in_uniform_table(wrapped_hue, gamutCuspTableSize);

    const float3 lo = reachGamutCuspTable[i_lo];
    const float3 hi = reachGamutCuspTable[i_lo + 1]; // Valid as we have added 1 to table length

    const float t = (wrapped_hue - lo.z) / (hi.z - lo.z);
    return lerp(lo.y, hi.y, t);
  }

  inline float daniele_evo_fwd(float Y)
  {
    Y       = Y / referenceLuminance;
    float f = daniele_m_2 * pow(max(0.0f, Y) / (Y + daniele_s_2), daniele_g);
    float h = max(0.0f, f * f / (f + daniele_t_1));
    return h * mmScaleFactor;
  }

  inline float daniele_evo_rev(float Y)
  {
    Y       = Y / mmScaleFactor;
    Y       = max(0.0f, min(daniele_n / (daniele_u_2 * daniele_n_r), Y));
    float h = (Y + sqrt(Y * (4.0f * daniele_t_1 + Y))) / 2.0f;
    float f = daniele_s_2 / (pow((daniele_m_2 / h), (1.0f / daniele_g)) - 1.0f);
    return f * referenceLuminance;
  }

  // Return compression gamut cusp M scaled with an eccentricity factor
  inline float eccentricity_factor(float hr)
  {
    float e_t = 1.0f;

    // clang-format off
    // CAM16
    if (cc_et == 0)
    {
      // NOTE: custom scaler 0.275 instead of 0.25 in CAM16
      e_t = 0.275f * (cos(2.0f + hr) + 3.8f);
    }
    // Hellwig2022
    // CAM16 vs Hellwig2022: https://onlinelibrary.wiley.com/cms/asset/60788dfc-6bae-4949-bf8d-bd8c3467aef8/col22792-fig-0005-m.jpg
    else if (cc_et == 1)
    {
      const float _h   = hr; // TODO: investigate spline implementation from Luke's PhD (A.15)
      const float _2_h = 2 * hr;
      const float _3_h = 3 * hr;
      const float _4_h = 4 * hr;
      e_t = (
        - 0.0582f * cos(_h)
        - 0.0258f * cos(_2_h)
        - 0.1347f * cos(_3_h)
        + 0.0289f * cos(_4_h)
        - 0.1475f * sin(_h)
        - 0.0308f * sin(_2_h)
        + 0.0385f * sin(_3_h)
        + 0.0096f * sin(_4_h)
        + 1.0f
      );
    }
    // Custom https://www.desmos.com/calculator/vukgp6rtos
    else if (cc_et == 2)
    {
      const float hr2 = hr * 2;
      const float hr3 = hr * 3;
      e_t = (-0.47f * cos(hr) +
              0.07f * cos(hr2) +
             -0.11f * cos(hr3) +
             -0.33f * sin(hr) +
              0.19f * sin(hr2) +
              0.00f * sin(hr3) +
              1.86f) * 0.58f;
    }
    // clang-format on

    return e_t;
  }

  // A "toe" function that remaps the given value x between 0 and limit.
  // The k1 and k2 parameters change the size and shape of the toe.
  // https://www.desmos.com/calculator/6vplvw14ti
  float toe(float x, float limit, float k1, float k2, int inverse)
  {
    if (x > limit)
      return x;

    k2       = max(k2, 0.001f);
    k1       = sqrt(k1 * k1 + k2 * k2);
    float k3 = (limit + k1) / (limit + k2);

    if (!inverse)
      return 0.5f * (k3 * x - k1 + sqrt((k3 * x - k1) * (k3 * x - k1) + 4 * k2 * k3 * x));
    else
      return (x * x + k1 * x) / (k3 * (x + k2));
  }

  // Chroma compression
  //
  // Compresses colors inside the gamut with the aim for colorfulness to have an
  // appropriate rate of change from display black to display white, and from
  // achromatic outward to purer colors.
  //
  float chromaCompression(float3 JMh, float origJ, int invert)
  {
    // Assumes 'h' component is wrapped [0.0, 360.0)
    float M = JMh.y;
    if (M == 0.0f)
      return M;

    float nJ    = JMh.x / limitJmax;
    float snJ   = max(0.0f, 1.0f - nJ);
    float Mnorm = ccuspFromTable(JMh.z).y;
    float limit = pow(nJ, model_gamma) * cReachFromTable(JMh.z) / Mnorm;

    if (!invert)
    {
      // Rescaling of M with the tonescaled J to get the M to the same range as
      // J after the tonescale.  The rescaling uses the Hellwig2022 model gamma to
      // keep the M/J ratio correct (keeping the chromaticities constant).
      M *= pow(JMh.x / origJ, model_gamma);

      // Normalize M with the rendering space cusp M
      M /= Mnorm;

      // Expand the colorfulness by running the toe function in reverse.  The goal is to
      // expand less saturated colors less and more saturated colors more.  The expansion
      // increases saturation in the shadows and mid-tones but not in the highlights.
      // The 0.001 offset starts the expansions slightly above zero.  The sat_thr makes
      // the toe less aggressive near black to reduce the expansion of noise.
      M = limit - toe(limit - M, limit - 0.001f, snJ * sat, sqrt(nJ * nJ + sat_thr), 0);

      // Compress the colorfulness.  The goal is to compress less saturated colors more and
      // more saturated colors less, especially in the highlights.  This step creates the
      // saturation roll-off in the highlights, but attemps to preserve pure colors.  This
      // mostly affects highlights and mid-tones, and does not compress shadows.
      M = toe(M, limit, nJ * compr, snJ, 0);

      // Denormalize
      M *= Mnorm;
    }
    else
    {
      M /= Mnorm;
      M = toe(M, limit, nJ * compr, snJ, 1);
      M = limit - toe(limit - M, limit - 0.001f, snJ * sat, sqrt(nJ * nJ + sat_thr), 1);
      M *= Mnorm;
      M *= pow(JMh.x / origJ, -model_gamma);
    }

    return M;
  }

  float3 clamp_to_AP1(float3 luminanceXYZ)
  {
    if (AP1Clamp)
    {
      float3 luminanceRGB   = vector_dot(XYZ_to_AP1, luminanceXYZ);
      luminanceRGB.x = max(0.0f, luminanceRGB.x);
      luminanceRGB.y = max(0.0f, luminanceRGB.y);
      luminanceRGB.z = max(0.0f, luminanceRGB.z);
      luminanceXYZ   = vector_dot(AP1_to_XYZ, luminanceRGB);
    }
    return luminanceXYZ;
  }

  inline float Y_to_Hellwig_J(float Y, float3 surround, int stage)
  {
    const float F_L_Y = pow(F_L[stage] * fabs(Y) / 100.0f, 0.42f);
    return sign(Y) * 100.0f * pow(((400.0f * F_L_Y) / (27.13f + F_L_Y)) / y_to_j_A_w[stage], surround.y * z[stage]);
  }

  inline float Hellwig_J_to_Y(float J, float3 surround, int stage)
  {
    const float A = y_to_j_A_w[stage] * pow(fabs(J) / 100.0f, 1.0f / (surround.y * z[stage]));
    return sign(J) * 100.0f / F_L[stage] * pow((27.13f * A) / (400.0f - A), 1.0f / 0.42f); // TODO: fix me
  }

  float3 forwardTonescale(float3 inputJMh, int conditions, int stage)
  {
    // Assumes 'h' component is wrapped [0.0, 360.0)
    if (!applyTonecurve)
    {
      return inputJMh;
    }

    float3 surround      = viewingConditionsToSurround(conditions);
    float  linear        = Hellwig_J_to_Y(inputJMh.x, surround, stage);
    float  luminanceTS   = daniele_evo_fwd(linear);
    float  tonemappedJ   = Y_to_Hellwig_J(luminanceTS, surround, stage);
    float3 tonemappedJMh = float3(tonemappedJ, inputJMh.y, inputJMh.z);

    return tonemappedJMh;
  }

  float3 compressChroma(float3 JMh, float originalJ, int inverse)
  {
    if (applyChromaCompression)
    {
      JMh.y = chromaCompression(JMh, originalJ, inverse);
      if (inverse)
        JMh.x = originalJ;
    }
    return JMh;
  }

  float3 inverseTonescale(float3 JMh, int conditions, int stage)
  {
    // Assumes 'h' component is wrapped [0.0, 360.0)
    if (!applyTonecurve)
    {
      return JMh;
    }

    float3 untonemappedColourJMh = JMh;
    float3 surround      = viewingConditionsToSurround(conditions);
    float  luminance     = Hellwig_J_to_Y(untonemappedColourJMh.x, surround, stage);
    float linear         = daniele_evo_rev(luminance);
    untonemappedColourJMh.x = Y_to_Hellwig_J(linear, surround, stage);

    return untonemappedColourJMh;
  }

  float2 hueDependantHullGammas(float wrapped_hue)
  {
    const int   i_lo     = hue_position_in_uniform_table(wrapped_hue, gamutCuspTableSize);
    const float base_hue = base_hue_for_position(i_lo, gamutCuspTableSize);
    const float t        = wrapped_hue - base_hue;

    return lerp(gamutGammas[i_lo], gamutGammas[i_lo + 1], t);
  }

  // reimplemented from https://github.com/nick-shaw/aces-ot-vwg-experiments/blob/master/python/intersection_approx.py
  float3 findGamutBoundaryIntersection(float3 JMh_s, float2 JM_cusp, float J_focus, float J_max, float slope_gain, float smoothness,
                                       float2 estimated_hull_gammas)
  {
    float2      JM_source    = float2(JMh_s.x, JMh_s.y);
    const float gamma_top    = estimated_hull_gammas.x;
    const float gamma_bottom = estimated_hull_gammas.y;

    float slope;

    JM_cusp *= smooth_cusp_scale; // TODO; could this be baked in?

    float J_intersect_source = solve_J_intersect(JM_source, J_focus, J_max, slope_gain);
    float J_intersect_cusp   = solve_J_intersect(JM_cusp, J_focus, J_max, slope_gain);

    if (J_intersect_source < J_focus)
    {
      slope = J_intersect_source * (J_intersect_source - J_focus) / (J_focus * slope_gain);
    }
    else
    {
      slope = (J_max - J_intersect_source) * (J_intersect_source - J_focus) / (J_focus * slope_gain);
    }

    float M_boundary_lower = J_intersect_cusp * pow(J_intersect_source / J_intersect_cusp, gamma_bottom) / (JM_cusp.x / JM_cusp.y - slope);

    float M_boundary_upper = JM_cusp.y * (J_max - J_intersect_cusp) * pow((J_max - J_intersect_source) / (J_max - J_intersect_cusp), gamma_top)
      / (slope * JM_cusp.y + J_max - JM_cusp.x);

    float M_boundary = JM_cusp.y * smin(M_boundary_lower / JM_cusp.y, M_boundary_upper / JM_cusp.y, smoothness);

    float J_boundary = J_intersect_source + slope * M_boundary;

    return float3(J_boundary, M_boundary, J_intersect_source);
  }

  float3 getReachBoundary(float3 Jmh)
  {
    // Assumes 'h' component is wrapped [0.0, 360.0)
    const float reachMaxM = cReachFromTable(Jmh.z);
  
    float2 JMcusp     = limitingCuspFromTable(Jmh.z);
    float  focusJ     = lerp(JMcusp.x, midJ, min(1.0f, cuspMidBlend - (JMcusp.x / limitJmax)));
    float  slope_gain = compute_slope_gain(Jmh.x, JMcusp.x);
    float  intersectJ = solve_J_intersect(float2(Jmh.x, Jmh.y), focusJ, limitJmax, slope_gain);
    float  slope;
    if (intersectJ < focusJ)
    {
      slope = intersectJ * (intersectJ - focusJ) / (focusJ * slope_gain);
    }
    else
    {
      slope = (limitJmax - intersectJ) * (intersectJ - focusJ) / (focusJ * slope_gain);
    }
    float boundaryNick = limitJmax * pow(intersectJ / limitJmax, model_gamma) * reachMaxM / (limitJmax - slope * reachMaxM);
    return float3(Jmh.x, boundaryNick, Jmh.z);
  }

  // https://www.desmos.com/calculator/oe2fscya80
  float getFocusGain(float J, float cuspJ)
  {
    if (disableFocusGain)
      return 1.0f;

    float thr = lerp(cuspJ, limitJmax, focusGainBlend);
    if (J > thr)
    {
      // Approximate inverse required above threshold // TODO
      float gain = (limitJmax - thr) / max(0.0001f, (limitJmax - min(limitJmax, J)));
      return pow(log10(gain), 1.0f / focusAdjustGain) + 1.0f;
    }
    else
    {
      // Analytic inverse possible below cusp // TODO is this comment correct
      return 1.0f;
    }
  }

  inline float compute_slope_gain(float J, float cuspJ)
  {
    return limitJmax * focusDist * getFocusGain(J, cuspJ);
  }

  float3 gamutMapper(float3 JMh, int invert)
  {
    if (!applyGamutCompression)
      return JMh;

    // Assumes 'h' component is wrapped [0.0, 360.0)
    if (disableFocusGain)
      return gamutMapper2(JMh, invert, JMh.x);

    if (!invert)
    {
      return gamutMapper2(JMh, 0, JMh.x);
    }
    else
    {
      float2 JMcusp = limitingCuspFromTable(JMh.z);
      float  Jx     = JMh.x;

      // Analytic inverse below threshold
      if (Jx <= lerp(JMcusp.x, limitJmax, focusGainBlend))
        return gamutMapper2(JMh, 1, Jx);

      // Approximation above
      Jx = gamutMapper2(JMh, 1, Jx).x;
      return gamutMapper2(JMh, 1, Jx);
    }
  }

  float3 gamutMapper2(float3 JMh, int invert, float Jx)
  {
    // Assumes 'h' component is wrapped [0.0, 360.0)
    const float2 project_from = float2(JMh.x, JMh.y);

    if (project_from.y == 0.0f) // TODO: should this be lowerMlimit
      return JMh;

    // Calculate where the out of gamut color is projected to
    float2 JMcusp     = limitingCuspFromTable(JMh.z);
    float  focusJ     = lerp(JMcusp.x, midJ, min(1.0f, cuspMidBlend - (JMcusp.x / limitJmax)));
    float  slope_gain = compute_slope_gain(Jx, JMcusp.x);

    // Find gamut intersection
    const float2 estimated_hull_gammas = hueDependantHullGammas(JMh.z);
    float3 ganutBoundary = findGamutBoundaryIntersection(JMh, JMcusp, focusJ, limitJmax, slope_gain, clamped_smoothness, estimated_hull_gammas);
    float2 JMboundary    = float2(ganutBoundary.x, ganutBoundary.y);
    float2 project_to    = float2(ganutBoundary.z, 0.0f);
    float  projectJ      = ganutBoundary.z;

    // Get hue dependent compression parameters
    const float3 JMh_boundary = float3(JMboundary.x, JMboundary.y, JMh.z);
    const float  locusMax     = getReachBoundary(JMh_boundary).y;
    const float  difference   = max(1.0001f, locusMax / JMh_boundary.y); // TODO: magic threshold?
    const float  threshold    = max(compressionFuncParams.x, 1.0f / difference);

    // Compress the out of gamut color along the projection line
    float2 JMcompressed;

    const float lowerMlimit = 0.0001f; // Testing a small value here // TODO
    if (JMh.x < limitJmax
        && JMh.y > lowerMlimit)        // using a small value to test against here rather than 0.0, and I was getting Nans on inversion.
    {
      float v      = project_from.y / JMboundary.y;
      v            = compressPowerP(v, threshold, difference, compressionFuncParams.w, invert);
      JMcompressed = project_to + v * (JMboundary - project_to);
    }
    else
    {
      JMcompressed = float2(JMh.x, 0.0f); // TODO: should this be lowerMlimit
    }
    return float3(JMcompressed.x, JMcompressed.y, JMh.z);
  }

  // Generate the Hellwig2022 post adaptation non-linear compression matrix
  // that is used in the inverse of the model (JMh-to-XYZ).
  //
  // Original:
  //  460.0f, 451.0f, 288.0f,
  //  460.0f, -891.0f, -261.0f,
  //  460.0f, -220.0f, -6300.0f
  void generate_panlrcm()
  {
    // clang-format off
    float panlrcm_data[]=
    {
      achromatic_weights.x, achromatic_weights.y, achromatic_weights.z,
      a_weights.x, a_weights.y, a_weights.z, 
      b_weights.x, b_weights.y, b_weights.z,
    };
    // clang-format on
    panlrcm.setArray(panlrcm_data);
    panlrcm = panlrcm.invert();

    for (int i = 0; i < 3; i++)
    {
      float n = (460.0f / panlrcm[i][0]) / 1403.0f;
      panlrcm[i][0] *= n;
      panlrcm[i][1] *= n;
      panlrcm[i][2] *= n;
    }
  }

  float3x3 generate_RGB_to_XYZ_matrix(const int which)
  {
    if (which == 0)
    {
      return RGBPrimsToXYZMatrix(float2(0.7347f, 0.2653), float2(0.0f, 1.0f), float2(0.0001, -0.077), float2(0.32168f, 0.33767f), 1.0f, 0);
    }
    else if (which == 1)
    {
      return RGBPrimsToXYZMatrix(float2(0.713f, 0.293f), float2(0.165f, 0.830f), float2(0.128f, 0.044f), float2(0.32168f, 0.33767f), 1.0f, 0);
    }
    else if (which == 2)
    {
      return RGBPrimsToXYZMatrix(float2(0.64f, 0.33f), float2(0.3f, 0.6f), float2(0.15f, 0.06f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 3)
    {
      return RGBPrimsToXYZMatrix(float2(0.708f, 0.292f), float2(0.170f, 0.797f), float2(0.131f, 0.046f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 4)
    {
      return RGBPrimsToXYZMatrix(float2(0.680f, 0.320f), float2(0.265f, 0.690f), float2(0.150f, 0.060f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 5)
    {
      return RGBPrimsToXYZMatrix(float2(0.680f, 0.320f), float2(0.265f, 0.690f), float2(0.150f, 0.060f), float2(0.314f, 0.351f), 1.0f, 0);
    }
    else
    {
      return identity_matrix;
    }
  }

  void init()
  {
    // pre-calculate Daniele Evo constants
    daniele_r_hit  = daniele_r_hit_min + (daniele_r_hit_max - daniele_r_hit_min) * (log(daniele_n / daniele_n_r) / log(10000.0f / 100.0f));
    daniele_m_0    = daniele_n / daniele_n_r;
    daniele_m_1    = 0.5f * (daniele_m_0 + sqrt(daniele_m_0 * (daniele_m_0 + 4.0f * daniele_t_1)));
    daniele_u      = pow((daniele_r_hit / daniele_m_1) / ((daniele_r_hit / daniele_m_1) + 1.0f), daniele_g);
    daniele_m      = daniele_m_1 / daniele_u;
    daniele_w_i    = log(daniele_n / 100.0f) / log(2.0f);
    daniele_c_t    = daniele_c_d * (1.0f + daniele_w_i * daniele_w_g) / daniele_n_r;
    daniele_g_ip   = 0.5f * (daniele_c_t + sqrt(daniele_c_t * (daniele_c_t + 4.0f * daniele_t_1)));
    daniele_g_ipp2 = -daniele_m_1 * pow(daniele_g_ip / daniele_m, 1.0f / daniele_g) / (pow(daniele_g_ip / daniele_m, 1.0f / daniele_g) - 1.0f);
    daniele_w_2    = daniele_c / daniele_g_ipp2;
    daniele_s_2    = daniele_w_2 * daniele_m_1;
    daniele_u_2    = pow((daniele_r_hit / daniele_m_1) / ((daniele_r_hit / daniele_m_1) + daniele_w_2), daniele_g);
    daniele_m_2    = daniele_m_1 / daniele_u_2;

    // 1.0f / (c * z) // TODO: investigate uses
    model_gamma = 1.0f / (viewingConditionsToSurround(outputViewingConditions).y * compute_base_exponential_nonlinearity(Y_b_out, L_A_out));

    clamped_smoothness  = max(0.000001f, smoothCusps);
    smooth_cusp_scale.x = 1.0f + smoothJ * clamped_smoothness; // TODO Do we need to translate in J
    smooth_cusp_scale.y = 1.0f + smoothM * clamped_smoothness;

    // Chroma compression scaling for HDR/SDR appearance match
    float log_peak = log10(daniele_n / daniele_n_r);
    compr          = chroma_compress + (chroma_compress * chroma_compress_fact) * log_peak;
    sat            = max(0.2f, chroma_expand - (chroma_expand * chroma_expand_fact) * log_peak); // TODO; magic number
    sat_thr        = chroma_expand_thr / daniele_n;

    // Gamut mapper focus distance scaling with peak luminance for
    // HDR/SDR appearance match.  The projection gets slightly less
    // steep with higher peak luminance.
    // https://www.desmos.com/calculator/bnfhjcq5vf
    if (!disableFocusDistScaling)
      focusDist = focusDistance + focusDistance * focusDistScaling * log_peak;
    else
      focusDist = focusDistance;

    float identity_matrix_data[] = {1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f};
    identity_matrix.setArray(identity_matrix_data);

    float CAT_CAT16_data[] = {
      0.401288, 0.650173, -0.051461, -0.250268, 1.204414, 0.045854, -0.002079, 0.048952, 0.953127,
    };

    // TODO; origin of numbers
    float Modified_CAT16_data[] = {
      0.656619, 0.342071, 0.00131062, -0.222571, 1.10658, 0.115987, -0.000634146, 0.05855, 0.942084,
    };

    // populate the input primaries matrix
    RGB_to_XYZ_input = generate_RGB_to_XYZ_matrix(primariesIn);

    // AP1 matrix
    AP1_to_XYZ = generate_RGB_to_XYZ_matrix(1); // AP1 == 1
    XYZ_to_AP1 = AP1_to_XYZ.invert();

    // populate the limiting primaries matrix
    // RGBPrimsToXYZMatrix
    float2 limitWhiteForMatrix;
    float2 limitRedForMatrix;
    float2 limitGreenForMatrix;
    float2 limitBlueForMatrix;
    if (whiteLimit == 0)
    {
      limitWhiteForMatrix = float2(0.32168f, 0.33767f);
    }
    else if (whiteLimit == 1)
    {
      limitWhiteForMatrix = float2(0.3127f, 0.3290f);
    }
    else
    {
      limitWhiteForMatrix = float2(0.333333f, 0.333333f);
    }

    // TODO: could we share these primaries with matrix generation code?
    if (primariesLimit == 0)
    {
      limitRedForMatrix   = float2(0.7347f, 0.2653f);
      limitGreenForMatrix = float2(0.0f, 1.0f);
      limitBlueForMatrix  = float2(0.0001f, -0.077f);
    }
    else if (primariesLimit == 1)
    {
      limitRedForMatrix   = float2(0.713f, 0.293f);
      limitGreenForMatrix = float2(0.165f, 0.830f);
      limitBlueForMatrix  = float2(0.128f, 0.044f);
    }
    else if (primariesLimit == 2)
    {
      limitRedForMatrix   = float2(0.64f, 0.33f);
      limitGreenForMatrix = float2(0.3f, 0.6f);
      limitBlueForMatrix  = float2(0.15f, 0.06f);
    }
    else if (primariesLimit == 3)
    {
      limitRedForMatrix   = float2(0.708f, 0.292f);
      limitGreenForMatrix = float2(0.170f, 0.797f);
      limitBlueForMatrix  = float2(0.131f, 0.046f);
    }
    else if (primariesLimit == 4)
    {
      limitRedForMatrix   = float2(0.680f, 0.320f);
      limitGreenForMatrix = float2(0.265f, 0.690f);
      limitBlueForMatrix  = float2(0.150f, 0.060f);
    }
    else
    {
      limitRedForMatrix   = float2(1.0f, 0.0f);
      limitGreenForMatrix = float2(0.0f, 1.0f);
      limitBlueForMatrix  = float2(0.0f, 0.0f);
    }

    RGB_to_XYZ_limit = RGBPrimsToXYZMatrix(limitRedForMatrix, limitGreenForMatrix, limitBlueForMatrix, limitWhiteForMatrix, 1.0f, 0);
    XYZ_to_RGB_limit = RGB_to_XYZ_limit.invert();

    RGB_to_XYZ_output = generate_RGB_to_XYZ_matrix(primariesOut);
    float3x3 XYZ_to_RGB_output = RGB_to_XYZ_output.invert();

    float3 white(1.0f, 1.0f, 1.0f);
    inWhite    = vector_dot(RGB_to_XYZ_input, white);
    limitWhite = vector_dot(RGB_to_XYZ_limit, white);

    if (catDataSelection == 0)
    {
      CAT_CAT16.setArray(CAT_CAT16_data);
    }
    else if (catDataSelection == 1)
    {
      CAT_CAT16.setArray(Modified_CAT16_data);
    }
    else if (catDataSelection == 2)
    {
      CAT_CAT16 = RGBPrimsToXYZMatrix(rxy, gxy, bxy, wxy, 1.0f, 1);
    }
    CAT_CAT16_INVERSE = CAT_CAT16.invert();

    achromatic_weights = float3(ra, 1.0f, ba);
    a_weights          = float3(11.0f, -12.0f, 1.0f) / 11.0f;
    b_weights          = float3(1.0f, 1.0f, -2.0f) / 9.0f;
    generate_panlrcm();

    precompute_hellwig(inWhite, inputViewingConditions, L_A, Y_b, discountIlluminant_in, 0);
    precompute_hellwig(limitWhite, outputViewingConditions, L_A_out, Y_b_out, discountIlluminant_out, 1);
    initialise_non_linearities();

    // calculate the maximum expected J & M values for the given limit gamut
    // these are used as limiting values for the gamut boundary searches
    // limitJmax (assumed to match limitRGB white)
    // BUG: this fails for HK mode as HK will be increased for highly saturated colours above white
    limitJmax = RGB_to_JMh(float3(1.0f), RGB_to_XYZ_limit).x;

    // Cusp table for Reach/chroma compression gamut
    float3x3 RGB_to_XYZ_cgReach;
    if (ccReach == 0) // Chroma Compression Space (primaries defined in kernel params)
    {
      RGB_to_XYZ_cgReach = RGBPrimsToXYZMatrix(crxy, cgxy, cbxy, cwxy, 1.0f, 0);
    }
    else if (ccReach == 1)
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(0);
    }
    else if (ccReach == 2)
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(1);
    }
    else
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(3);
    }
    const float3x3 XYZ_to_RGB_reach = RGB_to_XYZ_cgReach.invert();

    initialise_cusp_table(cgamutCuspTable, gamutCuspTableSize, RGB_to_XYZ_cgReach);
    initialise_reach_cusp_table(reachGamutCuspTable, gamutCuspTableSize, limitJmax, XYZ_to_RGB_reach);

    // Cusp table for limiting gamut
    initialise_cusp_table(limitingGamutCuspTable, gamutCuspTableSize, RGB_to_XYZ_limit);

    midJ = XYZ_to_JMh(limitWhite * daniele_c_t * mmScaleFactor, outputViewingConditions, HK_mode_out, 1).x;

    initialise_upper_hull_gamma();
    initialise_lower_hull_gamma();

    fitWhiteScale = 1.0f;
    if (fitWhite)
    {
      // Scale to fit maximum creative white channel value
      float3 creativeWhiteXYZ = vector_dot(RGB_to_XYZ_limit, float3(1.0f, 1.0f, 1.0f));
      float3 creativeWhiteRGB = vector_dot(XYZ_to_RGB_output, creativeWhiteXYZ);
      fitWhiteScale           = 1.0f / max(creativeWhiteRGB.x, max(creativeWhiteRGB.y, creativeWhiteRGB.z));
    }
  }

  inline float compute_base_exponential_nonlinearity(float Y_background, float Y_white)
  {
    return 1.48f + sqrt(Y_background / Y_white);
  }

  void precompute_hellwig(float3 referenceWhite, int conditions, float _L_A, float Y_b, bool discountIlluminant, int stage)
  {
    const float3 surround = viewingConditionsToSurround(conditions);

    const float3 XYZ_w_scaled = referenceWhite * XYZ_w_scaler;

    // # Step 0
    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
    const float3 RGB_w = vector_dot(CAT_CAT16, XYZ_w_scaled);

    // # Computing degree of adaptation :math:`D`.
    if (!discountIlluminant)
    {
      float D      = clamp(degree_of_adaptation(surround.x, _L_A), 0, 1);
      D_RGB[stage] = D * XYZ_w_scaled.y / RGB_w + 1 - D;
    }
    else
    {
      D_RGB[stage] = XYZ_w_scaled.y / RGB_w;
    }

    const float k  = 1.0f / (5.0f * _L_A + 1.0f);
    const float k4 = k * k * k * k;
    F_L[stage]     = 0.2f * k4 * (5.0f * _L_A) + 0.1f * pow((1.0f - k4), 2.0f) * pow(5.0f * _L_A, 1.0f / 3.0f);

    z[stage] = compute_base_exponential_nonlinearity(Y_b, XYZ_w_scaled.y);

    // # Computing achromatic responses for the whitepoint.
    const float3 RGB_wc = D_RGB[stage] * RGB_w;
    const float3 RGB_aw = post_adaptation_non_linear_response_compression_forward(RGB_wc, stage);
    A_w[stage]          = dot(achromatic_weights, RGB_aw);

    // Viewing conditions dependent parameters, different to A_w
    const float F_L_W = pow(F_L[stage], 0.42f);
    y_to_j_A_w[stage]  = (400.0f * F_L_W) / (27.13f + F_L_W);
  }

  void initialise_non_linearity(int stage)
  {
    nl_Fl_scaled[stage]        = F_L[stage] * nl_normalise;
    nl_derivative_scale[stage] = nl_d_scale * nl_Fl_scaled[stage];

    // Break point calculations
    nl_fql[stage]             = post_adaptation_non_linear_response_compression_forward_wheatley_f(ql, stage);
    nl_fqu[stage]             = post_adaptation_non_linear_response_compression_forward_wheatley_f(qu, stage);
    nl_lower_slope[stage]     = nl_fql[stage] / ql;
    nl_upper_slope[stage]     = post_adaptation_non_linear_response_compression_forward_derivative_wheatley(qu, stage);
    const float ql_derivative = post_adaptation_non_linear_response_compression_forward_derivative_wheatley(ql, stage);

    // precompute lower Quadratic parameters
    nl_a2[stage]            = (ql * ql_derivative - nl_fql[stage]) / (ql * ql);
    nl_a1[stage]            = ql_derivative - 2 * ql * nl_a2[stage];
    nl_a0[stage]            = 0.0; // TODO for now pass through origin
    nl_b_[stage]            = nl_a1[stage] / nl_a2[stage];
    nl_average_roots[stage] = -nl_b_[stage] / 2;
  }

  void initialise_non_linearities()
  {
    nl_gamma     = 0.42f;
    nl_normalise = 100.0f;
    nl_scale     = 400.0f;
    nl_offset    = 27.13f;
    nl_d_scale   = nl_gamma * nl_scale * nl_offset;

    for (int i = 0; i < 2; ++i)
    {
      initialise_non_linearity(i);
    }
  }

  void initialise_cusp_table(float3 * output_table, const int table_size, const float3x3& matrix)
  {
    // the 'tempTableUnsorted' table is populated
    // in increments of H of the limiting gamut HSV space starting at H=0.0
    // since it is unlikely that HSV.H=0 and JMh.h=0 line up
    // the entries are then wrap-around shifted
    // so that the 'gamutCuspTable' starts with the lowest JMh.h value
    float3 tempTableUnsorted[360];
    int    minhIndex = 0;
    for (int i = 0; i < table_size; ++i)
    {
      const float  hNorm   = float(i) / (table_size);
      const float3 RGB     = HSV_to_RGB(float3(hNorm, 1.0f, 1.0f));
      tempTableUnsorted[i] = RGB_to_JMh(RGB, matrix);
      if (tempTableUnsorted[i].z < tempTableUnsorted[minhIndex].z)
      {
        minhIndex = i;
      }
    }
    copy_table_rotated(tempTableUnsorted, table_size, output_table, minhIndex);

    // Add extra entry to wrap
    output_table[360]   = output_table[0];
    output_table[360].z = output_table[360].z + 360.0f;
  }

  void copy_table_rotated(float3 * tableUnsorted, const int tableSize, float3 output_table[], const int offsetIndex)
  {
    for (int i = 0; i < tableSize; ++i)
    {
      output_table[i] = tableUnsorted[(offsetIndex + i) % tableSize];
    }
  }

  void initialise_reach_cusp_table(float3 * output_table, const int table_size, const float limitJ, const float3x3& matrix)
  {
    const float search_range = 100.0;
    for (int i = 0; i < table_size; ++i)
    {
      const float hue = base_hue_for_position(i, table_size);

      float low     = 0.0;
      float high    = low + search_range;
      bool  outside = false;

      while (!outside && high < 1400.0)
      {
        outside = any_below_zero(JMh_to_RGB(float3(limitJ, high, hue), matrix));
        if (!outside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      while ((high - low) > 1e-2)
      {
        const float sampleM = (high + low) / 2.0;
        outside             = any_below_zero(JMh_to_RGB(float3(limitJ, sampleM, hue), matrix));
        if (outside)
        {
          high = sampleM;
        }
        else
        {
          low = sampleM;
        }
      }
      output_table[i].x = limitJ;
      output_table[i].y = high;
      output_table[i].z = hue;
    }
    // Wrap last entry in table
    output_table[table_size] = output_table[0];
    output_table[table_size].z += 360.0f;
  }

  inline bool outside_hull(const float3 newLimitRGB)
  {
    // limit value, once we cross this value, we are outside of the top gamut shell
    const float maxRGBtestVal = 1.0f;
    if (newLimitRGB.x > maxRGBtestVal || newLimitRGB.y > maxRGBtestVal || newLimitRGB.z > maxRGBtestVal)
    {
      return true;
    }
    return false;
  }

  bool evaluate_upper_hull_gamma_fit(const float2 JMcusp, float3 testJmh[], const int test_count, const float topGamma)
  {
    const float2 estimated_hull_gammas = float2(1.0f / topGamma, 1.0f / lowerHullGamma);
    const float  focusJ                = lerp(JMcusp.x, midJ, min(1.0, cuspMidBlend - (JMcusp.x / limitJmax)));

    for (int testIndex = 0; testIndex < test_count; ++testIndex)
    {
      const float  slope_gain  = compute_slope_gain(testJmh[testIndex].x, JMcusp.x);
      const float3 approxLimit =
        findGamutBoundaryIntersection(testJmh[testIndex], JMcusp, focusJ, limitJmax, slope_gain, clamped_smoothness, estimated_hull_gammas);
      const float3 approximate_JMh = float3(approxLimit.x, approxLimit.y, testJmh[testIndex].z);
      const float3 newLimitRGB     = JMh_to_RGB(approximate_JMh, XYZ_to_RGB_limit);

      if (!outside_hull(newLimitRGB))
      {
        return false;
      }
    }
    return true;
  }

  void initialise_upper_hull_gamma()
  {
    // Find upper hull gamma values for the gamut mapper
    // start by taking a h angle
    // get the cusp J value for that angle
    // find a J value halfway to the Jmax
    // iterate through gamma values until the approximate max M is negative through the actual boundary

    // positions between the cusp and Jmax we will check
    // variables that get set as we iterate through, once all are set to true we break the loop
    const int   test_count                = 3;
    const float testPositions[test_count] = {0.01f, 0.5f, 0.99f};
    for (int i = 0; i < gamutCuspTableSize; ++i)
    {
      if (disableUpperHullGamma)
      {
        gamutGammas[i].x = 1.0f / upperHullGamma;
        continue;
      }
      const float hue = base_hue_for_position(i, gamutCuspTableSize);
      //  default value. This will get overridden as we loop, but can be a good diagnostic to make sure things are working
      gamutGammas[i].x    = -1.0f;
      const float2 JMcusp = limitingCuspFromTable(hue);
      float3       testJmh[test_count];
      for (int testIndex = 0; testIndex < test_count; ++testIndex)
      {
        // create test values halfway between the cusp and the Jmax
        testJmh[testIndex] = float3(JMcusp.x + ((limitJmax - JMcusp.x) * testPositions[testIndex]), JMcusp.y, hue);
      }

      const float search_range = 0.4;
      float       low          = 0.4;
      float       high         = low + search_range;
      bool        all_inside   = false;

      while (!all_inside && high < 5.0)
      {
        all_inside = evaluate_upper_hull_gamma_fit(JMcusp, testJmh, test_count, high);
        if (!all_inside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      float testGamma = -1.0;
      while ((high - low) > 1e-5)
      {
        testGamma  = (high + low) / 2.0;
        all_inside = evaluate_upper_hull_gamma_fit(JMcusp, testJmh, test_count, testGamma);
        if (all_inside)
        {
          high = testGamma;
        }
        else
        {
          low = testGamma;
        }
      }
      gamutGammas[i].x = 1.0f / testGamma;
    }
    // Wrap the last entry
    gamutGammas[gamutCuspTableSize] = gamutGammas[0];
  }

  inline bool any_below_zero(const float3 newLimitRGB)
  {
    if (newLimitRGB.x < 0.0f || newLimitRGB.y < 0.0f || newLimitRGB.z < 0.0f)
    {
      return true;
    }
    return false;
  }

  bool evaluate_lower_hull_gamma_fit(const float2 JMcusp, float3 testJmh[], const int test_count, const float bottomGamma)
  {
    const float2 estimated_hull_gammas = float2(1.0f / upperHullGamma, 1.0f / bottomGamma);
    const float focusJ                 = lerp(JMcusp.x, midJ, cuspMidBlend);

    for (int testIndex = 0; testIndex < test_count; ++testIndex)
    {
      const float  slope_gain  = compute_slope_gain(testJmh[testIndex].x, JMcusp.x);
      const float3 approxLimit =
        findGamutBoundaryIntersection(testJmh[testIndex], JMcusp, focusJ, limitJmax, slope_gain, clamped_smoothness, estimated_hull_gammas);
      const float3 approximate_JMh = float3(approxLimit.x, approxLimit.y, testJmh[testIndex].z);
      const float3 newLimitRGB     = JMh_to_RGB(approximate_JMh, XYZ_to_RGB_limit);

      if (!any_below_zero(newLimitRGB))
      {
        return false;
      }
    }
    return true;
  }

  void initialise_lower_hull_gamma()
  {
    // Same process, for the bottom hull gamma
    const int   test_count                = 3;
    const float testPositions[test_count] = {0.01f, 0.4f, 0.75f};

    for (int i = 0; i < gamutCuspTableSize; ++i)
    {
      if (disableLowerHullGamma)
      {
        gamutGammas[i].y = 1.0f / lowerHullGamma;
        continue;
      }
      const float hue = base_hue_for_position(i, gamutCuspTableSize);

      gamutGammas[i].y    = -5.0f;
      const float2 JMcusp = limitingCuspFromTable(hue);
      float3       testJmh[test_count];
      for (int testIndex = 0; testIndex < test_count; ++testIndex)
      {
        testJmh[testIndex] = float3(JMcusp.x * testPositions[testIndex], JMcusp.y, hue);
      }

      const float search_range = 0.4;
      float       low          = 0.8;
      float       high         = low + search_range;
      bool        all_inside   = false;

      while (!all_inside && high < 5.0)
      {
        all_inside = evaluate_lower_hull_gamma_fit(JMcusp, testJmh, test_count, high);
        if (!all_inside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      float testGamma = -1.0;
      while ((high - low) > 1e-5)
      {
        testGamma  = (high + low) / 2.0;
        all_inside = evaluate_lower_hull_gamma_fit(JMcusp, testJmh, test_count, testGamma);
        if (all_inside)
        {
          high = testGamma;
        }
        else
        {
          low = testGamma;
        }
      }
      gamutGammas[i].y = 1.0f / testGamma;
    }
  }

  void process()
  {
    SampleType(src) source = src();
    float3 src(source.x, source.y, source.z);
    float3 inputXYZ;
    float3 JMh;
    float3 tonemappedJMh;
    float3 compressedJMh;
    float3 gamutMappedJMh;
    float3 outputXYZ;
    float3 diagnostic;

    if (!diagnosticMode)
    {
      if (invert)
      {
        gamutMappedJMh = XYZ_to_JMh(src, outputViewingConditions, HK_mode_out, 1);
        compressedJMh  = gamutMapper(gamutMappedJMh, 1);
        tonemappedJMh  = inverseTonescale(compressedJMh, inputViewingConditions, 0);
        JMh            = compressChroma(compressedJMh, tonemappedJMh.x, 1);
        diagnostic     = JMh_to_XYZ(JMh, inputViewingConditions, HK_mode_in, 0);
      }
      else
      {
        float3 clamped = clamp_to_AP1(src);
        JMh            = XYZ_to_JMh(clamped, inputViewingConditions, HK_mode_in, 0);
        tonemappedJMh  = forwardTonescale(JMh, inputViewingConditions, 0);
        compressedJMh  = compressChroma(tonemappedJMh, JMh.x, 0);
        gamutMappedJMh = gamutMapper(compressedJMh, 0);
        diagnostic     = JMh_to_XYZ(gamutMappedJMh, outputViewingConditions, HK_mode_out, 1);
      }
    }
    else
    {
      if (diagnosticMode == 1)
        diagnostic = clamp_to_AP1(src);
      else if (diagnosticMode == 2)
        diagnostic = XYZ_to_JMh(src, inputViewingConditions, HK_mode_in, 0);
      else if (diagnosticMode == 3)
        diagnostic = forwardTonescale(src, inputViewingConditions, 0);
      else if (diagnosticMode == 4)
{
        tonemappedJMh = forwardTonescale(src, inputViewingConditions, 0);
        diagnostic    = compressChroma(tonemappedJMh, src.x, 0);
      }
      else if (diagnosticMode == 5)
        diagnostic = gamutMapper(src, 0);
      else if (diagnosticMode == 6)
        diagnostic = JMh_to_XYZ(src, outputViewingConditions, HK_mode_out, 1);
      
      // Inverse steps
      else if (diagnosticMode == 11)
        diagnostic = XYZ_to_JMh(src, outputViewingConditions, HK_mode_out, 1);
      else if (diagnosticMode == 12)
        diagnostic = gamutMapper(src, 1);
      else if (diagnosticMode == 13)
        diagnostic = inverseTonescale(src, inputViewingConditions, 0);
      else if (diagnosticMode == 14)
      {
        tonemappedJMh = inverseTonescale(src, inputViewingConditions, 0);
        diagnostic    = compressChroma(src, tonemappedJMh.x, 1);
      }
      else if (diagnosticMode == 15)
        diagnostic = JMh_to_XYZ(src, inputViewingConditions, HK_mode_in, 0);
    }
    dst() = float4(diagnostic.x, diagnostic.y, diagnostic.z, source.w);
  }
};
