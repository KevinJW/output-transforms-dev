kernel DRT_CAM_Kernel : ImageComputationKernel<ePixelWise>
{
  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image
  Image<eWrite>                            dst; // the output image

param:
  //
  // Input Parameters
  //

  // Encoding of the Input Image
  // 0: Linear
  // 1: ACEScct
  // 2: sRGB
  // 3: BT.1886 (Gamma 2.4)
  // 4: Gamma 2.6
  // 5: ST2084
  int encodingIn;

  // AP1 clamp
  bool AP1Clamp;

  // Primaries of the Input Image
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65
  // 3: Rec.2020-D65
  // 4: P3-D65
  // 5: P3-DCI
  int primariesIn;

  // Tonescale mode
  // 0: Linear
  // 1: Daniele Evo Curve
  int toneScaleMode;

  // Disable Degree of Adaptation
  // This is only effective if the limit primaries have a non-D65 white point
  // since the input conversion is assumed to be fully adapted
  // and the output conversion does not apply a CAT
  bool discountIlluminant_in;
  bool discountIlluminant_mid;
  bool discountIlluminant_out;

  // Toggles for Hellwig 2022 specific params
  bool HK_mode_in;
  bool HK_mode_mid;
  bool HK_mode_out;
  int  compressMode;

  // Reference Luminance in Cd/sqm
  float referenceLuminance;

  // Viewing Conditions (for output)
  // 0: Dark
  // 1: Dim
  // 2: Average
  int viewingConditions;
  int outputViewingConditions;

  // Toggle Tone Mapping
  bool applyTonecurve;

  // Target Peak Luminance
  float peakLuminance;

  // Toggle chroma compression
  bool applyChromaCompression;
  bool applyInGamutExpansion;
  bool applyInGamutCompression;
  bool applyReachClamp;
  bool monochrome;

  // Chroma compression params
  float chroma_compress;
  float chroma_compress_fact;
  float chroma_expand;
  float chroma_expand_fact;
  float chroma_expand_thr;
  int   cc_et;
  int   ccReach;
  // xy coordinates for chroma compression gamut
  float2 crxy;
  float2 cgxy;
  float2 cbxy;
  float2 cwxy;

  //
  // Gamut Mapping Parameters
  //

  // Primaries of the Target Gamut
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65 # now just Rec.709
  // 3: Rec.2020-D65 # now just Rec.2020
  // 4: P3-D65 # now just P3
  // 5: P3-DCI # no longer included
  int primariesLimit;

  // White point of the limiting gamut
  // effectively the "creative white"
  // 0: ACES white
  // 1: D65
  // Could add others, or user white point
  int whiteLimit;

  // Primaries of the Gamut reached by the gamut compressor
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65
  // 3: Rec.2020-D65
  // 4: P3-D65
  // 5: P3-DCI
  // 6: Spectral Locus
  // 7: Chroma Compression Space
  int primariesReach;

  // Toggle Gamut Compression
  bool applyGamutCompression;

  // the 1D LUT used for quickly finding the approximate limiting gamut cusp JMh coordinates
  // the samples are spaced by HSV hue increments of the limiting RGB gamut
  // so to find the correct entry for a given CAM hue (h) value
  // one must search the table entries for the matching entry.z component
  int gamutCuspTableSize;

  // Blend Between Compressing towards
  // Target Gamut Cusp Luminance (0.0)
  // and Mid Luminance (1.0)
  float cuspMidBlend;

  // Focus distance of the compression focal point from the achromatic axis
  float focusDistance;
  float focusAdjustGain;
  float focusGainBlend;
  bool  disableFocusGain;
  bool  disableFocusDistScaling;
  float focusDistScaling;

  // Gamut Compression Fuction Parameters
  // Threshold / min Limit / max Limit / Power
  float4 compressionFuncParams;
  float4 compressionFuncParamsR; // Unused
  float4 compressionFuncParamsY; // Unused
  float4 compressionFuncParamsG; // Unused
  float4 compressionFuncParamsC; // Unused
  float4 compressionFuncParamsB; // Unused
  float4 compressionFuncParamsM; // Unused
  bool   Reachcompressmode; // Unused

  bool reachNick; // Unused
  bool sixAxisCompressionMode; // Unused
  bool Locuscompressmode; // Unused
  int  boundryIntersectionMethod; // Unused

  bool  disableUpperHullGamma;
  bool  disableLowerHullGamma;
  float lowerHullGamma;
  float upperHullGamma;

  // How much the edges of the target RGB cube are smoothed when finding the gamut boundary
  // in order to reduce visible contours at the gamut cusps
  float smoothCusps;
  float smoothJ; // Scaling factor for cusp J
  float smoothM; // Scaling factor for cusp M

  //
  // Output Parameters
  //

  // Encoding of the Output Image
  // 0: Linear
  // 1: ACEScct
  // 2: sRGB
  // 3: BT.1886 (Gamma 2.4)
  // 4: Gamma 2.6
  // 5: ST2084
  int encodingOut;

  // Primaries of the Output Image
  // 0: AP0-ACES
  // 1: AP1-ACES
  // 2: sRGB/Rec.709-D65
  // 3: Rec.2020-D65
  // 4: P3-D65
  // 5: P3-DCI
  int primariesOut;

  // Clamp output values to 0.0 - 1.0
  bool  fitWhite;
  bool  clampOutput;
  bool  softclampOutput;
  float clamp_thr;
  float clamp_dist;

  //
  // Extra Parameters
  //

  // Toggle Inverse Transform
  bool invert;
  // Diagnostic path modes
  int diagnosticMode;

  // DanieleEvoCurve (ACES2 candidate) parameters
  float mmScaleFactor;
  float daniele_n;         // peak white
  float daniele_n_r;       // Normalized white in nits (what 1.0 should be)
  float daniele_g;         // surround / contrast
  float daniele_c;         // scene-referred grey
  float daniele_c_d;       // display-referred grey (in nits)
  float daniele_w_g;       // grey change between different peak luminance
  float daniele_t_1;       // shadow toe, flare/glare compensation - how ever you want to call it
  float daniele_r_hit_min; // Scene-referred value "hitting the roof" at 100 nits
  float daniele_r_hit_max; // Scene-referred value "hitting the roof" at 10,000 nits

  // Hellwig 2022 CAM params
  // the kernel parameters

  // 0 = Stock CAT16
  // 1 = Thomas's custom primaries
  // 2 = live from params below
  int catDataSelection; // original vs modified CAT16 matrix
  // xy coordinates for custom CAT matrix
  float2 rxy;
  float2 gxy;
  float2 bxy;
  float2 wxy;
  float  ra;
  float  ba;

  // Input vars
  float3 XYZ_w;
  float  XYZ_w_scaler;
  float  L_A;
  float  Y_b;
  float3 L_B;
  float3 userSurround;
  bool   discount_illuminant;
  // Output vars
  float L_A_out;
  float Y_b_out;

  int nonlinearity_mode;
  float ql;
  float qu;
  float qz;

local:
  
  float3x3 CAT_CAT16;
  float3x3 CAT_CAT16_INVERSE;
  float3x3 panlrcm;

  float daniele_r_hit;
  float daniele_m_0;
  float daniele_m_1;
  float daniele_u;
  float daniele_m;
  float daniele_w_i;
  float daniele_c_t;
  float daniele_g_ip;
  float daniele_g_ipp2;
  float daniele_w_2;
  float daniele_s_2;
  float daniele_u_2;
  float daniele_m_2;

  // Chroma compression pre-calculated constants
  float compr;   // Compression
  float sat;     // Saturation
  float sat_thr; // Threshold to start expanding saturation

  // Gamut mapper constants
  float focusDist; // FocusDistance for projection

  // ST2084 vars
  float st2084_m_1;
  float st2084_m_2;
  float st2084_c_1;
  float st2084_c_2;
  float st2084_c_3;
  float st2084_m_1_d;
  float st2084_m_2_d;
  float st2084_L_p;

  // using the float3x3 type to store the array of 6 coefficients
  // because Blink does not support generic array assignments

  // matrix vars
  float3x3 identity_matrix;

  float3x3 XYZ_to_RGB_input;
  float3x3 XYZ_to_RGB_limit;
  float3x3 XYZ_to_RGB_reach;
  float3x3 XYZ_to_RGB_output;

  float3x3 RGB_to_XYZ_input;
  float3x3 RGB_to_XYZ_limit;
  float3x3 RGB_to_XYZ_reach;
  float3x3 RGB_to_XYZ_output;

  float3x3 AP1_to_XYZ;
  float3x3 XYZ_to_AP1;

  // white points
  float3 inWhite;
  float3 outWhite;
  float3 refWhite;
  float3 limitWhite;

  // the maximum lightness value of the limiting gamut
  float limitJmax;

  // Middle gray J
  float midJ;

  // Hellwig model's gamma (1 / cz)
  float model_gamma;

  // both tables need to be declared here since temporary array variables
  // in the init() fuction seem to crash Nuke on some systems
  float3 gamutCuspTable[360];
  float3 gamutCuspTableAP1[360];
  float3 gamutCuspTableReach[360];
  float3 cgamutCuspTable[360];
  float3 cgamutReachTable[360];
  float  gamutTopGamma[360];
  float  gamutBottomGamma[360];

  // Hellwig 2022 constants
  float F_L[3];
  float z[3];
  float3 D_RGB[3];
  float A_w[3];
  float3 achromatic_weights;
  float3 a_weights;
  float3 b_weights;

  // Nonlinearity 'constants'
  float nl_gamma;
  float nl_normalise;
  float nl_scale;
  float nl_offset;
  float nl_d_scale;

  // Per "stage" precomputed nonlinearity function variables
  float nl_Fl_scaled[3];
  float nl_derivative_scale[3];
  float nl_fql[3];
  float nl_fqu[3];
  float nl_lower_slope[3];
  float nl_upper_slope[3];
  float nl_a2[3];
  float nl_a1[3];
  float nl_a0[3];
  float nl_b_[3];
  float nl_average_roots[3];

  float fitWhiteScale;

  void define()
  {
    defineParam(chroma_compress_fact, "Chroma Compress Factor", 5.0f);
    defineParam(chroma_expand_fact, "Chroma Expansion Factor", 0.78f);
    defineParam(smoothJ, "Smoothing factor cusp J", 0.055f);
    defineParam(smoothM, "Smoothing factor cust M", 0.183f);

    defineParam(nonlinearity_mode, "Non-linearity Mode", 0);
    defineParam(ql, "Non-linearity Lower Break", 0.26f);
    defineParam(qu, "Non-linearity Upper Break", 150.0f);
    defineParam(qz, "Non-linearity intersection", 0.0f);
  }

  // Functions used in ACES 2.0 candidate CAM DRT

  // multiplies a 3D vector with a 3x3 matrix
  inline float3 vector_dot(const float3x3& m, const float3 v)
  {
    float3 r;
    for (int c = 0; c < 3; c++)
    {
      r[c] = m[c][0] * v.x + m[c][1] * v.y + m[c][2] * v.z;
    }

    return r;
  }

  // linear interpolation between two values a & b with the bias t
  inline float lerp(float a, float b, float t)
  {
    return a + t * (b - a);
  }
  inline float2 lerp(float2 a, float2 b, float t)
  {
    return a + t * (b - a);
  }
  inline float3 lerp(float3 a, float3 b, float t)
  {
    return a + t * (b - a);
  }
  inline float4 lerp(float4 a, float4 b, float t)
  {
    return a + t * (b - a);
  }

  inline float3 float3pow(float3 base, float exponent)
  {
    return float3(pow(base.x, exponent), pow(base.y, exponent), pow(base.z, exponent));
  }

  float degree_of_adaptation(float F, float _L_A)
  {
    float D = F * (1.0 - (1.0 / 3.6) * exp((-_L_A - 42.0f) / 92.0f));

    return D;
  }

  // convert radians to degrees
  inline float degrees(float radians)
  {
    return radians * 180.0f / PI;
  }

  // convert degrees to radians
  inline float radians(float degrees)
  {
    return degrees / 180.0f * PI;
  }

  // "PowerP" compression function (also used in the ACES Reference Gamut Compression transform)
  // values of v above  'threshold' are compressed by a 'power' function
  // so that an input value of 'limit' results in an output of 1.0
  float compressPowerP(float v, float threshold, float limit, float power, int inverse)
  {
    float s = (limit - threshold) / pow(pow((1.0f - threshold) / (limit - threshold), -power) - 1.0f, 1.0f / power);

    float vCompressed;

    if (inverse)
    {
      vCompressed = (v < threshold || limit < 1.0001f || v > threshold + s)
        ? v
        : threshold + s * pow(-(pow((v - threshold) / s, power) / (pow((v - threshold) / s, power) - 1.0f)), 1.0f / power);
    }
    else
    {
      vCompressed = (v < threshold || limit < 1.0001f)
        ? v
        : threshold + s * ((v - threshold) / s) / (pow(1.0f + pow((v - threshold) / s, power), 1.0f / power));
    }

    return vCompressed;
  }

  float3 compress_aces(float3 rgb, float3 c, float3 m, float3 y, int invert)
  {
    float  ach = max(rgb.x, max(rgb.y, rgb.z));
    float3 d   = 0.0f;

    if (ach)
    {
      d.x = (ach - rgb.x) / fabs(ach);
      d.y = (ach - rgb.y) / fabs(ach);
      d.z = (ach - rgb.z) / fabs(ach);
    }

    rgb.x = compressPowerP(d.x, c.x, c.y, c.z, invert);
    rgb.y = compressPowerP(d.y, m.x, m.y, m.z, invert);
    rgb.z = compressPowerP(d.z, y.x, y.y, y.z, invert);

    rgb = ach - rgb * fabs(ach);

    return rgb;
  }

  // Hellwig L, Stolitzka D,Fairchild MD.
  // Extending CIECAM02 and CAM16 for the Helmholtz–Kohlrausch effect.
  // Color Res Appl. 2022;1-9. doi:10.1002/col.22793 
  float hue_angle_dependency_Hellwig2022(float hr) 
  {
    return -0.160 * cos(hr) + 0.132 * cos(2 * hr) - 0.405 * sin(hr) + 0.080 * sin(2 * hr) + 0.792;
  }

  float3x3 RGBPrimsToXYZMatrix(float2 rxy, float2 gxy, float2 bxy, float2 wxy, float Y, bool direction)
  {
    // # given r g b chromaticities and whitepoint, convert RGB colors to XYZ
    // # based on CtlColorSpace.cpp from the CTL source code : 77
    // # param: xy - dict of chromaticity xy coordinates: rxy: float2(x, y) etc
    // # param: Y - luminance of "white" - defaults to 1.0
    // # param: inverse - calculate XYZ to RGB instead

    float2 r = rxy;
    float2 g = gxy;
    float2 b = bxy;
    float2 w = wxy;

    float X = w.x * Y / w.y;
    float Z = (1 - w.x - w.y) * Y / w.y;

    // # Scale factors for matrix rows
    float d = r.x * (b.y - g.y) + b.x * (g.y - r.y) + g.x * (r.y - b.y);

    float Sr =    (X * (b.y - g.y) -      \
            g.x * (Y * (b.y - 1.0f) +  \
            b.y * (X + Z)) +       \
            b.x * (Y * (g.y - 1.0f) + \
            g.y * (X + Z))) / d ;

    float Sg =    (X * (r.y - b.y) +      \
            r.x * (Y * (b.y - 1.0f) +  \
            b.y * (X + Z)) -        \
            b.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    float Sb =    (X * (g.y - r.y) -      \
            r.x * (Y * (g.y - 1.0f) +  \
            g.y * (X + Z)) +        \
            g.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    // # Assemble the matrix 
    float Mdata[] =
    {
      Sr * r.x, Sg * g.x, Sb * b.x,
      Sr * r.y, Sg * g.y, Sb * b.y,
      Sr * (1.0f - r.x - r.y), Sg * (1.0f - g.x - g.y), Sb * (1.0f - b.x - b.y),
    };

    float3x3 newMatrix;
    newMatrix.setArray(Mdata);

    // return forward or inverse matrix
    if (direction == 0)
    {
      return newMatrix;
    }
    else if (direction == 1)
    {
      // create inverse matrix
      float3x3 newMatrixInverse = newMatrix.invert();
      return newMatrixInverse;
    }
  }

  // convert ACEScct encoded values to linear
  float ACEScct_to_linear(float v)
  {
    return v > 0.155251141552511f ? pow(2.0f, v * 17.52f - 9.72f) : (v - 0.0729055341958355f) / 10.5402377416545f;
  }

  // encode linear values as ACEScct
  float linear_to_ACEScct(float v)
  {
    return v > 0.0078125f ? (log2(v) + 9.72f) / 17.52f : 10.5402377416545f * v + 0.0729055341958355f;
  }

  // convert sRGB gamma encoded values to linear
  float sRGB_to_linear(float v)
  {
    return v < 0.04045f ? v / 12.92f : pow((v + 0.055f) / 1.055f, 2.4f);
  }

  // encode linear values as sRGB gamma
  float linear_to_sRGB(float v)
  {
    return v <= 0.0031308f ? 12.92f * v : 1.055f * (pow(v, 1.0f / 2.4f)) - 0.055f;
  }

  float3 post_adaptation_non_linear_response_compression_forward_original(float3 RGB, int stage)
  {
    const float3 F_L_RGB = float3pow(F_L[stage] / 100.0f * fabs(RGB), 0.42f);
    const float3 RGB_c   = (400.0f * sign(RGB) * F_L_RGB) / (27.13f + F_L_RGB);
    return RGB_c;
  }

  float post_adaptation_non_linear_response_compression_forward_derivative_wheatley(float corresponding, int stage)
  {
    const float val   = fabs(corresponding);
    const float temp  = nl_derivative_scale[stage] * pow(nl_Fl_scaled[stage] * val, nl_gamma - 1.0f);
    const float temp1 = nl_offset + pow(nl_Fl_scaled[stage] * val, nl_gamma);
    return sign(corresponding) * temp / (temp1 * temp1);
  }

float post_adaptation_non_linear_response_compression_forward_original_f(float corresponding, int stage)
  {
    const float q      = fabs(corresponding);
    const float sign_c = sign(corresponding);
    const float temp   = pow(nl_Fl_scaled[stage] * q, nl_gamma);
    return sign_c * (nl_scale * (temp / (temp + nl_offset)));
  }

  float post_adaptation_non_linear_response_compression_forward_wheatley_f(float corresponding, int stage)
  {
    const float q = fabs(corresponding);
    const float sign_c = sign(corresponding);
    if (q > qu)
    {
        return sign_c * (nl_fqu[stage] + nl_upper_slope[stage] * (q - qu));
    }
    if (q < ql)
    {
        return sign_c * (nl_a2[stage] * q * q + nl_a1[stage] * q + nl_a0[stage]);
    }
    const float temp = pow(nl_Fl_scaled[stage] * q, nl_gamma);
    return sign_c * (nl_scale * (temp / (temp + nl_offset)));
  }

  float3 post_adaptation_non_linear_response_compression_forward_wheatley(float3 corresponding, int stage)
  {
    float3 non_linear;
    non_linear.x = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.x, stage);
    non_linear.y = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.y, stage);
    non_linear.z = post_adaptation_non_linear_response_compression_forward_wheatley_f(corresponding.z, stage);
    return non_linear;
  }

  inline float3 post_adaptation_non_linear_response_compression_forward(float3 RGB, int stage)
  {
    if (nonlinearity_mode == 1)
      return post_adaptation_non_linear_response_compression_forward_wheatley(RGB, stage);
    return post_adaptation_non_linear_response_compression_forward_original(RGB, stage);
  }

  float3 post_adaptation_non_linear_response_compression_inverse_original(float3 RGB, int stage)
  {
    const float3 absRGB = fabs(RGB);
    const float3 RGB_p  = sign(RGB) * 100.0f / F_L[stage] * float3pow((27.13f * absRGB) / (400.0f - absRGB), 1.0f / 0.42f);
    return RGB_p;
  }

  float post_adaptation_non_linear_response_compression_inverse_wheatley_f(float nl, int stage)
  {
    if (nl >= nl_fqu[stage])
    {
        return (nl - nl_fqu[stage]) / nl_upper_slope[stage] + qu;
    }
    if (nl <= nl_fql[stage])
    {
      // Quadratic solve
      const float c_ = nl / nl_a2[stage]; // TODO: no + a0
      const float u = sqrt(nl_average_roots[stage] * nl_average_roots[stage] + c_);
      return float(nl_average_roots[stage] - u); // (average_roots < u) ? average_roots + u : ... always take this root
    }

    const float temp = (nl_offset * nl) / (nl_scale - nl);
    return pow(temp, 1.0 / nl_gamma) / nl_Fl_scaled[stage];
  }

  float3 post_adaptation_non_linear_response_compression_inverse_wheatley(float3 nonlinear, int stage)
  {
    const float3 nl = fabs(nonlinear);
    const float3 sign_c = sign(nonlinear);
    float3 linear;
    linear.x = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.x, stage);
    linear.y = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.y, stage);
    linear.z = post_adaptation_non_linear_response_compression_inverse_wheatley_f(nl.z, stage);
    return sign_c * linear;
  }

  inline float3 post_adaptation_non_linear_response_compression_inverse(float3 RGB, int stage)
  {
    if (nonlinearity_mode == 1)
      return post_adaptation_non_linear_response_compression_inverse_wheatley(RGB, stage);
    return post_adaptation_non_linear_response_compression_inverse_original(RGB, stage);
  }


  // convert HSV cylindrical projection values to RGB
  float3 HSV_to_RGB(float3 HSV)
  {
    float C = HSV.z * HSV.y;
    float X = C * (1.0f - fabs(fmod(HSV.x * 6.0f, 2.0f) - 1.0f));
    float m = HSV.z - C;

    float3 RGB;
    RGB.x = (HSV.x < 1.0f / 6.0f     ? C
               : HSV.x < 2.0f / 6.0f ? X
               : HSV.x < 3.0f / 6.0f ? 0.0f
               : HSV.x < 4.0f / 6.0f ? 0.0f
               : HSV.x < 5.0f / 6.0f ? X
                                     : C)
      + m;
    RGB.y = (HSV.x < 1.0f / 6.0f     ? X
               : HSV.x < 2.0f / 6.0f ? C
               : HSV.x < 3.0f / 6.0f ? C
               : HSV.x < 4.0f / 6.0f ? X
               : HSV.x < 5.0f / 6.0f ? 0.0f
                                     : 0.0f)
      + m;
    RGB.z = (HSV.x < 1.0f / 6.0f     ? 0.0f
               : HSV.x < 2.0f / 6.0f ? 0.0f
               : HSV.x < 3.0f / 6.0f ? X
               : HSV.x < 4.0f / 6.0f ? C
               : HSV.x < 5.0f / 6.0f ? C
                                     : X)
      + m;
    return RGB;
  }

  // convert RGB to HSV cylindrical projection values
  float3 RGB_to_HSV(float3 RGB)
  {
    float cmax  = max(RGB.x, max(RGB.y, RGB.z));
    float cmin  = min(RGB.x, min(RGB.y, RGB.z));
    float delta = cmax - cmin;

    float3 HSV;
    HSV.x = delta == 0.0f ? 0.0f
      : cmax == RGB.x     ? (fmod((RGB.y - RGB.z) / delta + 6.0f, 6.0f)) / 6.0f
      : cmax == RGB.y     ? (((RGB.z - RGB.x) / delta + 2.0f) / 6.0f)
                          : (((RGB.x - RGB.y) / delta + 4.0f) / 6.0f);
    HSV.y = cmax == 0.0f ? 0.0f : delta / cmax;
    HSV.z = cmax;
    return HSV;
  }

  // Smooth minimum of a and b
  float smin(float a, float b, float s)
  {
    float h = max(s - fabs(a - b), 0.0) / s;
    return min(a, b) - h * h * h * s * (1.0f / 6.0f);
  }

  // reimplemented from https://github.com/nick-shaw/aces-ot-vwg-experiments/blob/master/python/intersection_approx.py
  float solve_J_intersect(float2 JM, float focusJ, float maxJ, float slope_gain)
  {
    float a          = JM.y / (focusJ * slope_gain);
    float b          = 0.0f;
    float c          = 0.0f;
    float intersectJ = 0.0f;

    if (JM.x < focusJ)
    {
      b = 1.0f - JM.y / slope_gain;
      c = -JM.x;
    }
    else
    {
      b = -(1.0f + JM.y / slope_gain + maxJ * JM.y / (focusJ * slope_gain));
      c = maxJ * JM.y / slope_gain + JM.x;
    }

    float root = sqrt(b * b - 4.0f * a * c);

    if (JM.x < focusJ)
    {
      intersectJ = 2.0f * c / (-b - root);
    }
    else
    {
      intersectJ = 2.0f * c / (-b + root);
    }

    return intersectJ;
  }

  float3 viewingConditionsToSurround(int viewingConditions)
  {
    float3 newSurround;
    // hack to turn incoming int value into surround coeffs
    if (viewingConditions == 0)
    {
      // "Dark": InductionFactors_CIECAM02(0.8, 0.525, 0.8),
      newSurround = float3(0.8, 0.525, 0.8);
    }
    else if (viewingConditions == 1)
    {
      // "Dim": InductionFactors_CIECAM02(0.9, 0.59, 0.9),
      newSurround = float3(0.9, 0.59, 0.9);
    }
    else if (viewingConditions == 2)
    {
      // "Average": InductionFactors_CIECAM02(1, 0.69, 1),
      newSurround = float3(1.0, 0.69, 1.0);
    }
    else if (viewingConditions == 3)
    {
      // Pull from external input
      newSurround = userSurround;
    }
    return newSurround;
  }

  // convert XYZ tristimulus values to the CAM J (lightness), M (colorfulness) and h (hue) correlates
  // needs XYZ tristimulus values for the reference white and the viewing conditions as parameters
  inline float3 XYZ_to_JMh(float3 XYZ, int viewingConditions, bool HK_mode, int stage)
  {
    return XYZ_to_Hellwig2022_JMh(XYZ, viewingConditionsToSurround(viewingConditions), HK_mode, stage);
  }

  // convert the CAM J (lightness), M (colorfulness) and h (hue) correlates to XYZ tristimulus values
  // needs XYZ tristimulus values for the reference white and the viewing conditions as parameters
  inline float3 JMh_to_XYZ(float3 JMh, int viewingConditions, bool HK_mode, int stage)
  {
    return Hellwig2022_JMh_to_XYZ(JMh, viewingConditionsToSurround(viewingConditions), HK_mode, stage);
  }

  // convert ST2084 PQ encoded values to linear
  float ST2084_to_linear(float v)
  {
    float V_p = pow(v, st2084_m_2_d);
    return pow((max(0.0f, V_p - st2084_c_1) / (st2084_c_2 - st2084_c_3 * V_p)), st2084_m_1_d) * st2084_L_p;
  }

  // encode linear values as ST2084 PQ
  float linear_to_ST2084(float v)
  {
    float Y_p = pow(max(0.0f, v) / st2084_L_p, st2084_m_1);
    return pow((st2084_c_1 + st2084_c_2 * Y_p) / (st2084_c_3 * Y_p + 1.0f), st2084_m_2);
  }

  // decode value 'v' with the inverse of the selected encoding fuction to luminance
  float encodingToLuminance(int encoding, float v)
  {
    if (encoding == 1)
    {
      // ACEScct
      return ACEScct_to_linear(v) * referenceLuminance;
    }
    else if (encoding == 2)
    {
      // sRGB
      return sRGB_to_linear(v) * referenceLuminance;
    }
    else if (encoding == 3)
    {
      // BT.1886 (Gamma 2.4)
      return pow(v, 2.4f) * referenceLuminance;
    }
    else if (encoding == 4)
    {
      // Gamma 2.6
      return pow(v, 2.6f) * referenceLuminance;
    }
    else if (encoding == 5)
    {
      // ST2084
      return ST2084_to_linear(v);
    }
    else
    {
      // Linear
      // default
      return v * referenceLuminance;
    }
  }

  // decode the components of a 3D vector 'v' with the inverse of the selected encoding fuction to luminance
  float3 encodingToLuminance3(int encoding, float3 v)
  {
    float3 lin;
    lin.x = encodingToLuminance(encoding, v.x);
    lin.y = encodingToLuminance(encoding, v.y);
    lin.z = encodingToLuminance(encoding, v.z);

    return lin;
  }

  // encode the linear luminance value 'v' with the encoding fuction selected by 'encoding'
  float luminanceToEncoding(int encoding, float v)
  {
    if (encoding == 1)
    {
      // ACEScct
      return linear_to_ACEScct(v / referenceLuminance);
    }
    else if (encoding == 2)
    {
      // sRGB
      return linear_to_sRGB(v / referenceLuminance);
    }
    else if (encoding == 3)
    {
      // BT.1886 (Gamma 2.4)
      return pow(v / referenceLuminance, 1.0f / 2.4f);
    }
    else if (encoding == 4)
    {
      // Gamma 2.6
      return pow(v / referenceLuminance, 1.0f / 2.6f);
    }
    else if (encoding == 5)
    {
      // ST2084
      return linear_to_ST2084(v);
    }
    else
    {
      // Linear
      // default
      return v / referenceLuminance;
    }
  }

  // encode the linear luminance value components of a 3D vector 'v' with the encoding fuction selected by 'encoding'
  float3 luminanceToEncoding3(int encoding, float3 v)
  {
    float3 enc;
    enc.x = luminanceToEncoding(encoding, v.x);
    enc.y = luminanceToEncoding(encoding, v.y);
    enc.z = luminanceToEncoding(encoding, v.z);

    return enc;
  }

  // convert RGB values in the output colorspace to the CAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 output_RGB_to_JMh(float3 RGB)
  {
    float3 luminanceRGB = encodingToLuminance3(encodingOut, RGB);
    float3 XYZ          = vector_dot(RGB_to_XYZ_output, luminanceRGB);
    float3 JMh          = XYZ_to_JMh(XYZ, viewingConditions, HK_mode_out, 2);
    return JMh;
  }

  // convert RGB values in the output colorspace to the CAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 luminance_RGB_to_JMh(float3 luminanceRGB)
  {
    float3 XYZ = vector_dot(RGB_to_XYZ_output, luminanceRGB);
    float3 JMh = XYZ_to_JMh(XYZ, outputViewingConditions, HK_mode_mid, 1);
    return JMh;
  }

  // convert CAM J (lightness), M (colorfulness) and h (hue) correlates to  RGB values in the output colorspace
  float3 JMh_to_output_RGB(float3 JMh)
  {
    float3 luminanceXYZ = JMh_to_XYZ(JMh, outputViewingConditions, HK_mode_out, 2);

    // switch to treat incoming data as luminanceXYZ when in breakout mode
    if (diagnosticMode == 105)
    {
      luminanceXYZ = JMh;
    }

    // First matrix to limiting gamut for clamping
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_limit, luminanceXYZ);
    luminanceRGB *= fitWhiteScale;

    if (softclampOutput)
    {
      // Soft clamp by compressing negative display linear values
      float3 compr = float3(clamp_thr, clamp_dist, 1.2f);
      luminanceRGB = compress_aces(luminanceRGB, compr, compr, compr, 0);
    }

    if (clampOutput)
    {
      // Clamp to between zero and peak luminance
      luminanceRGB = clamp(luminanceRGB, 0.0f, peakLuminance);
    }

    // Matrix to output (encoding) gamut (eventually concatenate to a single matrix)
    luminanceRGB = vector_dot(RGB_to_XYZ_limit, luminanceRGB);
    luminanceRGB = vector_dot(XYZ_to_RGB_output, luminanceRGB);

    // return luminanceRGB when in breakout mode
    if (diagnosticMode == 105)
    {
      return luminanceRGB;
    }

    float3 outputRGB = luminanceToEncoding3(encodingOut, luminanceRGB);

    return outputRGB;
  }

  // convert CAM J (lightness), M (colorfulness) and h (hue) correlates to  RGB values in the output colorspace
  float3 JMh_to_luminance_RGB(float3 JMh)
  {
    float3 luminanceXYZ = JMh_to_XYZ(JMh, outputViewingConditions, HK_mode_mid, 1);
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_output, luminanceXYZ);

    return luminanceRGB;
  }

  // convert linear RGB values with the given primaries to CAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 RGB_to_JMh(const float3 RGB, const float3x3& matrix)
  {
    const float3 luminanceRGB = RGB * peakLuminance;
    const float3 XYZ          = vector_dot(matrix, luminanceRGB);
    const float3 JMh          = XYZ_to_JMh(XYZ, viewingConditions, HK_mode_mid, 1);
    return JMh;
  }

  // convert CAM J (lightness), M (colorfulness) and h (hue) correlates to linear RGB values with the given primaries
  float3 JMh_to_RGB(float3 JMh, const float3x3& matrix)
  {
    float3 luminanceXYZ = JMh_to_XYZ(JMh, viewingConditions, HK_mode_mid, 1);
    float3 luminanceRGB = vector_dot(matrix, luminanceXYZ);
    float3 RGB          = luminanceRGB / peakLuminance;
    return RGB;
  }

  // XYZ to Hellwig2020 JMh
  //
  //     XYZ
  //         *CIE XYZ* tristimulus values of test sample / stimulus.
  //     XYZ_w
  //         *CIE XYZ* tristimulus values of reference white.
  //     L_A
  //         Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`, (often taken
  //         to be 20% of the luminance of a white object in the scene).
  //     Y_b
  //         Luminous factor of background :math:`Y_b` such as
  //         :math:`Y_b = 100 x L_b / L_w` where :math:`L_w` is the luminance of the
  //         light source and :math:`L_b` is the luminance of the background. For
  //         viewing images, :math:`Y_b` can be the average :math:`Y` value for the
  //         pixels in the entire image, or frequently, a :math:`Y` value of 20,
  //         approximate an :math:`L^*` of 50 is used.
  //     surround
  //         Surround viewing conditions induction factors.
  //         Truth value indicating if the illuminant should be discounted.
  //     discount_illuminant
  //
  // NOTE: Following modifications have been made to stock Hellwig2022 model for this DRT:
  //
  // - Custom primaries
  // - Eccentriticty factor has been removed
  // - Compress mode
  //
  float3 XYZ_to_Hellwig2022_JMh(float3 XYZ, float3 surround, bool HK_mode, int stage)
  {
        // # Step 1
    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
    float3 RGB = vector_dot(CAT_CAT16, XYZ);

    // # Step 2
    float3 RGB_c = D_RGB[stage] * RGB;

    // # Step 3
    // # Applying forward post-adaptation non-linear response compression.

    float3 RGB_a = post_adaptation_non_linear_response_compression_forward(RGB_c, stage);

    // # Step 6 and Step 4
    // # Computing achromatic responses for the stimulus.
    // # Converting to preliminary cartesian coordinates.
    // basically a 3x3 matrix

    const float A = dot(achromatic_weights, RGB_a);
    const float a = dot(a_weights, RGB_a);
    const float b = dot(b_weights, RGB_a);

    // # Computing the *hue* angle :math:`h`.
    const float hr = atan2(b, a);
    const float h  = wrap_to_360(degrees(hr));

    // # Step 7
    // # Computing the correlate of *Lightness* :math:`J`.
    float J = 100.0f * pow(A / A_w[stage], surround.y * z[stage]);

    // # Step 8
    // # Computing the correlate of *brightness* :math:`Q`.
    // float Q = (2.0f / float(surround.y)) * (J / 100.0f) * A_w[stage];

    // # Step 9
    // # Computing the correlate of *colourfulness* :math:`M`.
    float M = 43.0f * surround.z * sqrt(a * a + b * b);

    // # Computing the correlate of *saturation* :math:`s`.
    // float s = 100.0f * div(M, Q); // possible div by 0
  
    if (HK_mode)
    {
      // # Computing the correlate of *chroma* :math:`C`.
      const float C = 35.0f * M / A_w[stage];
      // # *Helmholtz–Kohlrausch* Effect Extension.
      J = J + hue_angle_dependency_Hellwig2022(hr) * pow(C, 0.587f); // TODO: Luke's PhD has updated HK calculation
      // float Q_HK = (2.0f / surround.y) * (J / 100.0f) * A_w[stage];
    }
    
    if (J == 0.0f)
      M = 0.0f;
    return {J, M, h};
  }

  float3 Hellwig2022_JMh_to_XYZ(float3 JMh, float3 surround, bool HK_mode, int stage)
  {
    float J = JMh.x;
    const float M = JMh.y;
    const float hr = radians(JMh.z);

    // # *Helmholtz–Kohlrausch* Effect Extension.
    const float C = (M * 35.0f) / A_w[stage];
    if (HK_mode)
    {
      J = J - hue_angle_dependency_Hellwig2022(hr) * pow(C, 0.587f);
    }

    // # Computing achromatic response :math:`A` for the stimulus.
    const float A = A_w[stage] * pow(J / 100.0f, 1.0f / (surround.y * z[stage]));

    // # Computing *P_p_1* to *P_p_2*.
    const float P_p_1 = 43.0f * surround.z;
    const float P_p_2 = A;

    // # Step 3
    // # Computing opponent colour dimensions :math:`a` and :math:`b`.
    const float gamma = M / P_p_1;
    const float a     = gamma * cos(hr);
    const float b     = gamma * sin(hr);

    // # Step 4
    // # Applying post-adaptation non-linear response compression matrix.
    const float3 RGB_a = vector_dot(panlrcm, float3(P_p_2, a, b));

    // # Step 5
    // # Applying inverse post-adaptation non-linear response compression.
    const float3 RGB_c = post_adaptation_non_linear_response_compression_inverse(RGB_a, stage);

    // # Step 6
    const float3 RGB = RGB_c / D_RGB[stage];

    // # Step 7
    const float3 XYZ = vector_dot(CAT_CAT16_INVERSE, RGB);

    return XYZ;
  }

  // retrieve the JM coordinates of the limiting gamut cusp at the hue slice 'h'
  // cusps are very expensive to compute
  // and the DRT is only using them for lightness mapping
  // which does not require a high degree of accuracy
  // so instead we use a pre-computed table of cusp points
  // sampled at 1 degree hue intervals of the the RGB target gamut
  // and lerp between them to get the approximate J & M values

  inline int midpoint(int low, int high)
  {
    return int((high + low) / 2); // Integer division
  }

  int find_upper_hue_in_table(float h, float3 *table, int table_size)
  {
    int low_i  = 0;
    int high_i = table_size - 1;
    int i      = hue_position_in_uniform_table(h, table_size);

    while (low_i + 1 < high_i)
    {
      if (h > table[i].z)
      {
        low_i = i;
      }
      else
      {
        high_i = i;
      }
      i = midpoint(low_i, high_i);
    }
    return high_i;
  }

  float2 cuspFromTable(float h)
  {
    float3 lo;
    float3 hi;
    if (h <= gamutCuspTable[0].z)
    {
      lo   = gamutCuspTable[gamutCuspTableSize - 1];
      lo.z = lo.z - 360.0f;
      hi   = gamutCuspTable[0];
    }
    else if (h >= gamutCuspTable[gamutCuspTableSize - 1].z)
    {
      lo   = gamutCuspTable[gamutCuspTableSize - 1];
      hi   = gamutCuspTable[0];
      hi.z = hi.z + 360.f;
    }
    else
    {
      int low_i  = 0;
      int high_i = gamutCuspTableSize - 1;
      int i      = hue_position_in_uniform_table(h, gamutCuspTableSize);

      while (low_i + 1 < high_i)
      {
        if (h > gamutCuspTable[i].z)
        {
          low_i = i;
        }
        else
        {
          high_i = i;
        }
        i = midpoint(low_i, high_i);
      }
      lo = gamutCuspTable[high_i - 1];
      hi = gamutCuspTable[high_i];
    }

    float t = (h - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ, cuspM);
  }

  float2 cuspFromTableAP1(float h)
  {

    float3 lo;
    float3 hi;

    if (h <= gamutCuspTableAP1[0].z)
    {
      lo   = gamutCuspTableAP1[gamutCuspTableSize - 1];
      lo.z = lo.z - 360.0f;
      hi   = gamutCuspTableAP1[0];
    }
    else if (h >= gamutCuspTableAP1[gamutCuspTableSize - 1].z)
    {
      lo   = gamutCuspTableAP1[gamutCuspTableSize - 1];
      hi   = gamutCuspTableAP1[0];
      hi.z = hi.z + 360.f;
    }
    else
    {
      int low_i  = 0;
      int high_i = gamutCuspTableSize - 1;
      int i      = hue_position_in_uniform_table(h, gamutCuspTableSize);

      while (low_i + 1 < high_i)
      {
        if (h > gamutCuspTableAP1[i].z)
        {
          low_i = i;
        }
        else
        {
          high_i = i;
        }
        i = midpoint(low_i, high_i);
      }
      lo = gamutCuspTableAP1[high_i - 1];
      hi = gamutCuspTableAP1[high_i];
    }

    float t = (h - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ, cuspM);
  }

  float2 ccuspFromTable(float h)
  {
    float3 lo;
    float3 hi;

    if (h <= cgamutCuspTable[0].z)
    {
      lo   = cgamutCuspTable[gamutCuspTableSize - 1];
      lo.z = lo.z - 360.0f;
      hi   = cgamutCuspTable[0];
    }
    else if (h >= cgamutCuspTable[gamutCuspTableSize - 1].z)
    {
      lo   = cgamutCuspTable[gamutCuspTableSize - 1];
      hi   = cgamutCuspTable[0];
      hi.z = hi.z + 360.f;
    }
    else
    {
      int low_i  = 0;
      int high_i = gamutCuspTableSize - 1;
      int i      = hue_position_in_uniform_table(h, gamutCuspTableSize);

      while (low_i + 1 < high_i)
      {
        if (h > cgamutCuspTable[i].z)
        {
          low_i = i;
        }
        else
        {
          high_i = i;
        }
        i = midpoint(low_i, high_i);
      }
      lo = cgamutCuspTable[high_i - 1];
      hi = cgamutCuspTable[high_i];
    }

    float t = (h - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ, cuspM);
  }

  inline float wrap_to_360(float hue)
  {
    float y = fmod(hue, 360.0f);
    if (y < 0.0)
    {
      y = y + 360.0f;
    }
    return y;
  }

  inline int hue_position_in_uniform_table(float hue, int table_size)
  {
    const float wrapped_hue = wrap_to_360(hue);
    return int(wrapped_hue / 360.0f * table_size);
  }

  inline int next_position_in_table(int entry, int table_size)
  {
    return (entry + 1) % table_size;
  }

  inline float base_hue_for_position(int i_lo, int table_size)
  {
    return float(i_lo) * 360.0f / float(table_size);
  }

  float cReachFromTable(float h)
  {
    const int i_lo = hue_position_in_uniform_table(h, gamutCuspTableSize);
    const int i_hi = next_position_in_table(i_lo, gamutCuspTableSize);

    const float3 lo = cgamutReachTable[i_lo];
    const float3 hi = cgamutReachTable[i_hi];

    const float t = (h - lo.z) / (hi.z - lo.z);
    return lerp(lo.y, hi.y, t);
  }

  float daniele_evo_fwd(float Y)
  {
    float f = daniele_m_2 * pow(max(0.0f, Y) / (Y + daniele_s_2), daniele_g);
    float h = max(0.0f, f * f / (f + daniele_t_1));
    return h;
  }

  float daniele_evo_rev(float Y)
  {
    Y       = max(0.0f, min(daniele_n / (daniele_u_2 * daniele_n_r), Y));
    float h = (Y + sqrt(Y * (4.0f * daniele_t_1 + Y))) / 2.0f;
    float f = daniele_s_2 / (pow((daniele_m_2 / h), (1.0f / daniele_g)) - 1.0f);
    return f;
  }

  // Return compression gamut cusp M scaled with an eccentricity factor
  float eccentricity_factor(float h)
  {
    const float hr = radians(h);

    float e_t = 1.0f;

    // CAM16
    if (cc_et == 0)
    {
      // NOTE: custom scaler 0.275 instead of 0.25 in CAM16
      e_t = 0.275f * (cos(2.0f + hr) + 3.8f);
    }
    // Hellwig2022
    // CAM16 vs Hellwig2022: https://onlinelibrary.wiley.com/cms/asset/60788dfc-6bae-4949-bf8d-bd8c3467aef8/col22792-fig-0005-m.jpg
    else if (cc_et == 1)
    {
      const float _h   = hr; // TODO: investigate spline implementation from Luke's PhD (A.15)
      const float _2_h = 2 * hr;
      const float _3_h = 3 * hr;
      const float _4_h = 4 * hr;
      e_t = (
        -0.0582f * cos(_h)
        - 0.0258f * cos(_2_h)
        - 0.1347f * cos(_3_h)
        + 0.0289f * cos(_4_h)
        - 0.1475f * sin(_h)
        - 0.0308f * sin(_2_h)
        + 0.0385f * sin(_3_h)
        + 0.0096f * sin(_4_h)
        + 1.0f
      );
    }
    // Custom https://www.desmos.com/calculator/vukgp6rtos
    else if (cc_et == 2)
    {
      const float hr2 = hr * 2;
      const float hr3 = hr * 3;
      e_t = (-0.47f * cos(hr) +
              0.07f * cos(hr2) +
             -0.11f * cos(hr3) +
             -0.33f * sin(hr) +
              0.19f * sin(hr2) +
              0.00f * sin(hr3) +
              1.86f) * 0.58f;
    }
    return e_t;
  }

  float cusp_with_eccentricity_factor(float h)
  {
    const float2 JMcusp = ccuspFromTable(h);
    return JMcusp.y * eccentricity_factor(h);
  }

  // A "toe" function that remaps the given value x between 0 and limit.
  // The k1 and k2 parameters change the size and shape of the toe.
  // https://www.desmos.com/calculator/6vplvw14ti
  float toe(float x, float limit, float k1, float k2, int inverse)
  {
    if (x > limit)
      return x;

    k2       = max(k2, 0.001f);
    k1       = sqrt(k1 * k1 + k2 * k2);
    float k3 = (limit + k1) / (limit + k2);

    if (!inverse)
      return 0.5f * (k3 * x - k1 + sqrt((k3 * x - k1) * (k3 * x - k1) + 4 * k2 * k3 * x));
    else
      return (x * x + k1 * x) / (k3 * (x + k2));
  }

  // Chroma compression
  //
  // Compresses colors inside the gamut with the aim for colorfulness to have an
  // appropriate rate of change from display black to display white, and from
  // achromatic outward to purer colors.
  //
  float chromaCompression(float3 JMh, float origJ, float linear, int invert)
  {
    float M = JMh.y;
    if (M == 0.0f)
      return M;

    float nJ    = JMh.x / limitJmax;
    float snJ   = max(0.0f, 1.0f - nJ);
    float Mnorm = cusp_with_eccentricity_factor(JMh.z);
    float limit = pow(nJ, model_gamma) * cReachFromTable(JMh.z) / Mnorm;

    if (!invert)
    {
      // Rescaling of M with the tonescaled J to get the M to the same range as
      // J after the tonescale.  The rescaling uses the Hellwig2022 model gamma to
      // keep the M/J ratio correct (keeping the chromaticities constant).
      M *= pow(JMh.x / origJ, model_gamma);

      if (applyInGamutCompression)
      {
        // Normalize M with the rendering space cusp M
        M /= Mnorm;

        // Expand the colorfulness by running the toe function in reverse.  The goal is to
        // expand less saturated colors less and more saturated colors more.  The expansion
        // increases saturation in the shadows and mid-tones but not in the highlights.
        // The 0.001 offset starts the expansions slightly above zero.  The sat_thr makes
        // the toe less aggressive near black to reduce the expansion of noise.
        if (applyInGamutExpansion)
          M = limit - toe(limit - M, limit - 0.001f, snJ * sat, sqrt(nJ * nJ + sat_thr), 0);

        // Compress the colorfulness.  The goal is to compress less saturated colors more and
        // more saturated colors less, especially in the highlights.  This step creates the
        // saturation roll-off in the highlights, but attemps to preserve pure colors.  This
        // mostly affects highlights and mid-tones, and does not compress shadows.
        M = toe(M, limit, nJ * compr, snJ, 0);

        // Clamp M to the rendering space
        if (applyReachClamp)
          M = min(limit, M);

        // Denormalize
        M *= Mnorm;
      }
    }
    else
    {
      if (applyInGamutCompression)
      {
        M /= Mnorm;
        M = toe(M, limit, nJ * compr, snJ, 1);
        if (applyInGamutExpansion)
          M = limit - toe(limit - M, limit - 0.001f, snJ * sat, sqrt(nJ * nJ + sat_thr), 1);
        M *= Mnorm;
      }

      M *= pow(JMh.x / origJ, -model_gamma);
    }

    return M;
  }

  float3 input_RGB_to_JMh(float3 inputRGB)
  {
    // convert to linear XYZ luminance values
    float3 luminanceRGB = encodingToLuminance3(encodingIn, inputRGB);
    float3 luminanceXYZ = vector_dot(RGB_to_XYZ_input, luminanceRGB);

    if (AP1Clamp)
    {
      luminanceRGB   = vector_dot(XYZ_to_AP1, luminanceXYZ);
      luminanceRGB.x = max(0.0f, luminanceRGB.x);
      luminanceRGB.y = max(0.0f, luminanceRGB.y);
      luminanceRGB.z = max(0.0f, luminanceRGB.z);
      luminanceXYZ   = vector_dot(AP1_to_XYZ, luminanceRGB);
    }

    float3 JMh = XYZ_to_JMh(luminanceXYZ, viewingConditions, HK_mode_in, 0);

    if (diagnosticMode == 6 || diagnosticMode == 100)
    {
      return luminanceXYZ;
    }
    else
    {
      return JMh;
    }
  }

  float3 JMh_to_input_RGB(float3 JMh)
  {
    float3 luminanceXYZ = JMh_to_XYZ(JMh, viewingConditions, HK_mode_in, 0);
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_input, luminanceXYZ);
    float3 inputRGB     = luminanceToEncoding3(encodingIn, luminanceRGB);

    return inputRGB;
  }

float Y_to_Hellwig_J(float Y, float3 surround, int stage)
  {
    // Viewing conditions dependent parameters (could be pre-calculated)
    const float _F_L  = F_L[stage];
    const float F_L_W = pow(_F_L, 0.42f); // TODO: fix me
    const float _A_w  = (400.0f * F_L_W) / (27.13f + F_L_W);

    const float F_L_Y = pow(_F_L * fabs(Y) / 100.0f, 0.42f);
    return sign(Y) * 100.0f * pow(((400.0f * F_L_Y) / (27.13f + F_L_Y)) / _A_w, surround.y * z[stage]);
  }

  float Hellwig_J_to_Y(float J, float3 surround, int stage)
  {
    // Viewing conditions dependent parameters (could be pre-calculated)
    const float _F_L   = F_L[stage];
    const float F_L_W  = pow(_F_L, 0.42f); // TODO: fix me
    const float _A_w   = (400.0f * F_L_W) / (27.13f + F_L_W);

    const float A = _A_w * pow(fabs(J) / 100.0f, 1.0f / (surround.y * z[stage]));
    return sign(J) * 100.0f / _F_L * pow((27.13f * A) / (400.0f - A), 1.0f / 0.42f); // TODO: fix me
  }

  float3 forwardTonescale(float3 inputJMh, int stage)
  {
    float3 outputJMh;
    float3 surround    = viewingConditionsToSurround(viewingConditions);
    float  linear      = Hellwig_J_to_Y(inputJMh.x, surround, stage) / referenceLuminance;
    float  luminanceTS = linear;

    // switch for applying the different tonescale compression functions
    if (toneScaleMode == 1)
    {
      luminanceTS = daniele_evo_fwd(luminanceTS) * mmScaleFactor;
    }

    float  tonemappedJ   = Y_to_Hellwig_J(luminanceTS, surround, stage);
    float3 tonemappedJMh = float3(tonemappedJ, inputJMh.y, inputJMh.z);

    if (applyTonecurve)
    {
      outputJMh = tonemappedJMh;
    }
    else
    {
      outputJMh = inputJMh;
    }

    if (applyChromaCompression)
    {
      outputJMh.y = chromaCompression(tonemappedJMh, inputJMh.x, linear, 0);
    }

    if (monochrome)
    {
      outputJMh.y = 0.0f;
    }

    return outputJMh;
  }

  float3 inverseTonescale(float3 JMh, int stage)
  {
    float3 tonemappedJMh = JMh;
    float3 surround = viewingConditionsToSurround(viewingConditions);

    if (!applyTonecurve && !applyChromaCompression)
    {
      // nothing else to do here
      return tonemappedJMh;
    }

    float3 untonemappedColourJMh = tonemappedJMh;

    float luminance = Hellwig_J_to_Y(tonemappedJMh.x, surround, stage);

    // Dummy value to init the var
    float linear = 0.0f;
    if (toneScaleMode == 1)
    {
      linear = daniele_evo_rev(luminance / mmScaleFactor);
    }
    else
    {
      linear = luminance;
    }

    linear = linear * referenceLuminance;

    if (applyTonecurve)
    {
      float untonemappedJ = Y_to_Hellwig_J(linear, surround, stage);
      untonemappedColourJMh = float3(untonemappedJ, tonemappedJMh.y, tonemappedJMh.z);
    }

    if (applyChromaCompression)
    {
      untonemappedColourJMh.y = chromaCompression(tonemappedJMh, untonemappedColourJMh.x, linear, 1);
    }

    return untonemappedColourJMh;
  }

  float hueDependantUpperHullGamma(float h)
  {
    if (disableUpperHullGamma)
      return upperHullGamma;

    const int i_lo = hue_position_in_uniform_table(h, gamutCuspTableSize);
    const int i_hi = next_position_in_table(i_lo, gamutCuspTableSize);

    const float base_hue = base_hue_for_position(i_lo, gamutCuspTableSize);
    const float t        = h - base_hue;

    return lerp(gamutTopGamma[i_lo], gamutTopGamma[i_hi], t);
  }

  float hueDependantLowerHullGamma(float h)
  {
    if (disableLowerHullGamma)
      return lowerHullGamma;

    const int i_lo = hue_position_in_uniform_table(h, gamutCuspTableSize);
    const int i_hi = next_position_in_table(i_lo, gamutCuspTableSize);

    const float base_hue = base_hue_for_position(i_lo, gamutCuspTableSize);
    const float t        = h - base_hue;

    return lerp(gamutBottomGamma[i_lo], gamutBottomGamma[i_hi], t);
  }

  // reimplemented from https://github.com/nick-shaw/aces-ot-vwg-experiments/blob/master/python/intersection_approx.py
  float3 findGamutBoundaryIntersection(float3 JMh_s, float2 JM_cusp, float J_focus, float J_max, float slope_gain, float smoothness,
                                       float2 estimated_hull_gammas)
  {
    float2 JM_source         = float2(JMh_s.x, JMh_s.y);
    const float gamma_top    = estimated_hull_gammas.x;
    const float gamma_bottom = estimated_hull_gammas.y;

    float slope = 0.0f;

    float s = max(0.000001f, smoothness);
    JM_cusp.x *= 1.0f + smoothJ * s; // J
    JM_cusp.y *= 1.0f + smoothM * s; // M

    float J_intersect_source = solve_J_intersect(JM_source, J_focus, J_max, slope_gain);
    float J_intersect_cusp   = solve_J_intersect(JM_cusp, J_focus, J_max, slope_gain);

    if (J_intersect_source < J_focus)
    {
      slope = J_intersect_source * (J_intersect_source - J_focus) / (J_focus * slope_gain);
    }
    else
    {
      slope = (J_max - J_intersect_source) * (J_intersect_source - J_focus) / (J_focus * slope_gain);
    }

    float M_boundary_lower = J_intersect_cusp * pow(J_intersect_source / J_intersect_cusp, 1 / gamma_bottom) / (JM_cusp.x / JM_cusp.y - slope);

    float M_boundary_upper = JM_cusp.y * (J_max - J_intersect_cusp)
      * pow((J_max - J_intersect_source) / (J_max - J_intersect_cusp), 1.0f / gamma_top) / (slope * JM_cusp.y + J_max - JM_cusp.x);

    float M_boundary = JM_cusp.y * smin(M_boundary_lower / JM_cusp.y, M_boundary_upper / JM_cusp.y, s);

    float J_boundary = J_intersect_source + slope * M_boundary;

    return float3(J_boundary, M_boundary, J_intersect_source);
  }

  // Approximation of the gamut intersection to a curved and smoothened triangle
  // along the projection line 'from -> to'.
  float2 find_gamut_intersection(float2 cusp, float2 from, float2 to, float smoothing)
  {
    float t0, t1;

    // Scale the cusp outward when smoothing to avoid reducing the gamut.  Reduce
    // smoothing for high cusps because smin() will bias it too much for the longer line.
    float s = max(lerp(smoothing, smoothing * 0.05f, cusp.x / limitJmax), 0.0001f);
    cusp.y *= 1.0f + 0.18f * s; // TODO: magic numbers
    cusp.x *= 1.0f + 0.07f * s;

    // Line below the cusp is curved with model_gamma
    float toJ_gamma   = cusp.x * pow(to.x / cusp.x, model_gamma);
    float fromJ_gamma = cusp.x * pow(from.x / cusp.x, model_gamma);
    t0                = cusp.y * toJ_gamma / (from.y * cusp.x + cusp.y * (toJ_gamma - fromJ_gamma));

    // Line above the cusp
    t1 = cusp.y * (to.x - limitJmax) / (from.y * (cusp.x - limitJmax) + cusp.y * (to.x - from.x));

    // Smooth minimum to smooth the cusp
    t1 = smin(fabs(t0), fabs(t1), s);

    return float2(to.x * (1.0f - t1) + t1 * from.x, t1 * from.y);
  }

  float3 getReachBoundry(float3 Jmh)
  {
    const float h = Jmh.z;

    const int i_lo = hue_position_in_uniform_table(h, gamutCuspTableSize);
    const int i_hi = next_position_in_table(i_lo, gamutCuspTableSize);

    const float3 lo = gamutCuspTableReach[i_lo];
    const float3 hi = gamutCuspTableReach[i_hi];

    const float t = (h - lo.z) / (hi.z - lo.z);

    const float reachMaxM = lerp(lo.y, hi.y, t);

    float2 JMcusp     = cuspFromTable(Jmh.z);
    float  focusJ     = lerp(JMcusp.x, midJ, min(1.0f, cuspMidBlend - (JMcusp.x / limitJmax)));
    float  slope_gain = limitJmax * focusDist * getFocusGain(Jmh.x, JMcusp.x);
    float  intersectJ = solve_J_intersect(float2(Jmh.x, Jmh.y), focusJ, limitJmax, slope_gain);
    float  slope;
    if (intersectJ < focusJ)
    {
      slope = intersectJ * (intersectJ - focusJ) / (focusJ * slope_gain);
    }
    else
    {
      slope = (limitJmax - intersectJ) * (intersectJ - focusJ) / (focusJ * slope_gain);
    }
    float boundaryNick = limitJmax * pow(intersectJ / limitJmax, model_gamma) * reachMaxM / (limitJmax - slope * reachMaxM);
    return float3(Jmh.x, boundaryNick, Jmh.z);
  }

  // https://www.desmos.com/calculator/oe2fscya80
  float getFocusGain(float J, float cuspJ)
  {
    if (disableFocusGain)
      return 1.0f;

    float thr = lerp(cuspJ, limitJmax, focusGainBlend);
    if (J > thr)
    {
      // Approximate inverse required above threshold // TODO
      float gain = (limitJmax - thr) / max(0.0001f, (limitJmax - min(limitJmax, J)));
      return pow(log10(gain), 1.0f / focusAdjustGain) + 1.0f;
    }
    else
    {
      // Analytic inverse possible below cusp
      return 1.0f;
    }
  }

  float3 compressGamut(float3 JMh, int invert)
  {
    if (disableFocusGain)
      return compressGamut2(JMh, invert, JMh.x);

    if (!invert)
    {
      return compressGamut2(JMh, 0, JMh.x);
    }
    else
    {
      float2 JMcusp = cuspFromTable(JMh.z);
      float  Jx     = JMh.x;

      // Analytic inverse below threshold
      if (Jx <= lerp(JMcusp.x, limitJmax, focusGainBlend))
        return compressGamut2(JMh, 1, Jx);

      // Approximation above
      Jx = compressGamut2(JMh, 1, Jx).x;
      return compressGamut2(JMh, 1, Jx);
    }
  }

  float3 compressGamut2(float3 JMh, int invert, float Jx)
  {
    const float2 project_from = float2(JMh.x, JMh.y);

    if (!applyGamutCompression)
      return JMh;
    if (project_from.y == 0.0f)
      return JMh;

    // Calculate where the out of gamut color is projected to
    float2 JMcusp     = cuspFromTable(JMh.z);
    float  focusJ     = lerp(JMcusp.x, midJ, min(1.0f, cuspMidBlend - (JMcusp.x / limitJmax)));
    float  slope_gain = limitJmax * focusDist * getFocusGain(Jx, JMcusp.x);
  
    // Find gamut intersection 
    float2 estimated_hull_gammas = float2(hueDependantUpperHullGamma(JMh.z), hueDependantLowerHullGamma(JMh.z));
    float3 nickBoundryReturn = findGamutBoundaryIntersection(JMh, JMcusp, focusJ, limitJmax, slope_gain, smoothCusps, estimated_hull_gammas);
    float2 JMboundary        = float2(nickBoundryReturn.x, nickBoundryReturn.y);
    float2 project_to        = float2(nickBoundryReturn.z, 0.0f);
    float  projectJ          = nickBoundryReturn.z;

    // Get hue dependent compression parameters
    const float3 JMh_boundary = float3(JMboundary.x, JMboundary.y, JMh.z);
    float locusMax   = getReachBoundry(JMh_boundary).y;
    float difference = max(1.0001f, locusMax / JMh_boundary.y); // TODO: magic threshold?
    float threshold  = max(compressionFuncParams.x, 1.0f / difference);
    float4 interpolatedCompressionFuncParams = float4(threshold, difference, difference, compressionFuncParams.w);

    // Compress the out of gamut color along the projection line
    float2 JMcompressed = project_from;

    float lowerMlimit = 0.0001f; // Testing a small value here // TODO
    if (JMh.x < limitJmax
        && JMh.y > lowerMlimit)  // using a small value to test against here rather than 0.0, and I was getting Nans on inversion.
    {
      float v      = project_from.y / JMboundary.y;
      v            = compressPowerP(v, interpolatedCompressionFuncParams.x,
                                    lerp(interpolatedCompressionFuncParams.z, interpolatedCompressionFuncParams.y, projectJ / limitJmax),
                                    interpolatedCompressionFuncParams.w, invert);
      JMcompressed = project_to + v * (JMboundary - project_to);
    }
    else
    {
      JMcompressed = float2(JMh.x, 0.0f);
    }

    if (diagnosticMode == 12)
    {
      return float3(JMboundary.x, JMboundary.y, JMh.z);
    }
    if (diagnosticMode == 18)
    {
      return float3(JMh.x, JMboundary.y, JMh.z);
    }
    if (diagnosticMode == 20)
    {
      // return focus point
      return float3(project_to.x, project_to.y, JMh.z);
    }
    // actual output
    else
    {
      return float3(JMcompressed.x, JMcompressed.y, JMh.z);
    }
  }

  // Generate the Hellwig2022 post adaptation non-linear compression matrix
  // that is used in the inverse of the model (JMh-to-XYZ).
  //
  // Original:
  //  460.0f, 451.0f, 288.0f,
  //  460.0f, -891.0f, -261.0f,
  //  460.0f, -220.0f, -6300.0f
  void generate_panlrcm()
  {
    float panlrcm_data[]=
    {
      achromatic_weights.x, achromatic_weights.y, achromatic_weights.z,
      a_weights.x, a_weights.y, a_weights.z, 
      b_weights.x, b_weights.y, b_weights.z, 
    };
    panlrcm.setArray(panlrcm_data);
    panlrcm = panlrcm.invert();

    for (int i = 0; i < 3; i++)
    {
      float n = (460.0f / panlrcm[i][0]) / 1403.0f;
      panlrcm[i][0] *= n;
      panlrcm[i][1] *= n;
      panlrcm[i][2] *= n;
    }
  }

  float3x3 generate_RGB_to_XYZ_matrix(const int which)
  {
    if (which == 0)
    {
      return RGBPrimsToXYZMatrix(float2(0.7347f, 0.2653), float2(0.0f, 1.0f), float2(0.0001, -0.077), float2(0.32168f, 0.33767f), 1.0f, 0);
    }
    else if (which == 1)
    {
      return RGBPrimsToXYZMatrix(float2(0.713f, 0.293f), float2(0.165f, 0.830f), float2(0.128f, 0.044f), float2(0.32168f, 0.33767f), 1.0f, 0);
    }
    else if (which == 2)
    {
      return RGBPrimsToXYZMatrix(float2(0.64f, 0.33f), float2(0.3f, 0.6f), float2(0.15f, 0.06f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 3)
    {
      return RGBPrimsToXYZMatrix(float2(0.708f, 0.292f), float2(0.170f, 0.797f), float2(0.131f, 0.046f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 4)
    {
      return RGBPrimsToXYZMatrix(float2(0.680f, 0.320f), float2(0.265f, 0.690f), float2(0.150f, 0.060f), float2(0.3127f, 0.3290f), 1.0f, 0);
    }
    else if (which == 5)
    {
      return RGBPrimsToXYZMatrix(float2(0.680f, 0.320f), float2(0.265f, 0.690f), float2(0.150f, 0.060f), float2(0.314f, 0.351f), 1.0f, 0);
    }
    else
    {
      return identity_matrix;
    }
  }

  void init()
  {
    st2084_m_1   = 2610.0f / 4096.0f * (1.0f / 4.0f);
    st2084_m_2   = 2523.0f / 4096.0f * 128.0f;
    st2084_c_1   = 3424.0f / 4096.0f;
    st2084_c_2   = 2413.0f / 4096.0f * 32.0f;
    st2084_c_3   = 2392.0f / 4096.0f * 32.0f;
    st2084_m_1_d = 1.0f / st2084_m_1;
    st2084_m_2_d = 1.0f / st2084_m_2;
    st2084_L_p   = 10000.0f;

    // pre-calculate Daniele Evo constants
    daniele_r_hit  = daniele_r_hit_min + (daniele_r_hit_max - daniele_r_hit_min) * (log(daniele_n / daniele_n_r) / log(10000.0f / 100.0f));
    daniele_m_0    = daniele_n / daniele_n_r;
    daniele_m_1    = 0.5f * (daniele_m_0 + sqrt(daniele_m_0 * (daniele_m_0 + 4.0f * daniele_t_1)));
    daniele_u      = pow((daniele_r_hit / daniele_m_1) / ((daniele_r_hit / daniele_m_1) + 1.0f), daniele_g);
    daniele_m      = daniele_m_1 / daniele_u;
    daniele_w_i    = log(daniele_n / 100.0f) / log(2.0f);
    daniele_c_t    = daniele_c_d * (1.0f + daniele_w_i * daniele_w_g) / daniele_n_r;
    daniele_g_ip   = 0.5f * (daniele_c_t + sqrt(daniele_c_t * (daniele_c_t + 4.0f * daniele_t_1)));
    daniele_g_ipp2 = -daniele_m_1 * pow(daniele_g_ip / daniele_m, 1.0f / daniele_g) / (pow(daniele_g_ip / daniele_m, 1.0f / daniele_g) - 1.0f);
    daniele_w_2    = daniele_c / daniele_g_ipp2;
    daniele_s_2    = daniele_w_2 * daniele_m_1;
    daniele_u_2    = pow((daniele_r_hit / daniele_m_1) / ((daniele_r_hit / daniele_m_1) + daniele_w_2), daniele_g);
    daniele_m_2    = daniele_m_1 / daniele_u_2;

    // 1.0f / (c * z) // TODO: investigate uses
    model_gamma = 1.0f / (viewingConditionsToSurround(outputViewingConditions).y * compute_base_exponential_nonlinearity(Y_b_out, L_A_out));

    // Chroma compression scaling for HDR/SDR appearance match
    float log_peak = log10(daniele_n / daniele_n_r);
    compr          = chroma_compress + (chroma_compress * chroma_compress_fact) * log_peak;
    sat            = max(0.2f, chroma_expand - (chroma_expand * chroma_expand_fact) * log_peak); // TODO; magic number
    sat_thr        = chroma_expand_thr / daniele_n;

    // Gamut mapper focus distance scaling with peak luminance for
    // HDR/SDR appearance match.  The projection gets slightly less
    // steep with higher peak luminance.
    // https://www.desmos.com/calculator/bnfhjcq5vf
    if (!disableFocusDistScaling)
      focusDist = focusDistance + focusDistance * focusDistScaling * log_peak;
    else
      focusDist = focusDistance;

    float identity_matrix_data[] = {1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f};
    identity_matrix.setArray(identity_matrix_data);

    float CAT_CAT16_data[] = {
      0.401288, 0.650173, -0.051461, -0.250268, 1.204414, 0.045854, -0.002079, 0.048952, 0.953127,
    };

    // TODO; origin of numbers
    float Modified_CAT16_data[] = {
      0.656619, 0.342071, 0.00131062, -0.222571, 1.10658, 0.115987, -0.000634146, 0.05855, 0.942084,
    };

   // populate the input primaries matrix
    RGB_to_XYZ_input = generate_RGB_to_XYZ_matrix(primariesIn);
    XYZ_to_RGB_input = RGB_to_XYZ_input.invert();

    // AP1 matrix
    AP1_to_XYZ = generate_RGB_to_XYZ_matrix(1); // AP1 == 1
    XYZ_to_AP1 = AP1_to_XYZ.invert();

    // populate the limiting primaries matrix
    // RGBPrimsToXYZMatrix
    float2 limitWhiteForMatrix;
    float2 limitRedForMatrix;
    float2 limitGreenForMatrix;
    float2 limitBlueForMatrix;
    if (whiteLimit == 0)
    {
      limitWhiteForMatrix = float2(0.32168f, 0.33767f);
    }
    else if (whiteLimit == 1)
    {
      limitWhiteForMatrix = float2(0.3127f, 0.3290f);
    }
    else
    {
      limitWhiteForMatrix = float2(0.333333f, 0.333333f);
    }

    // TODO: could we share these primaries with matrix generation code?
    if (primariesLimit == 0)
    {
      limitRedForMatrix   = float2(0.7347f, 0.2653);
      limitGreenForMatrix = float2(0.0f, 1.0f);
      limitBlueForMatrix  = float2(0.0001, -0.077);
    }
    else if (primariesLimit == 1)
    {
      limitRedForMatrix   = float2(0.713f, 0.293f);
      limitGreenForMatrix = float2(0.165f, 0.830f);
      limitBlueForMatrix  = float2(0.128f, 0.044f);
    }
    else if (primariesLimit == 2)
    {
      limitRedForMatrix   = float2(0.64f, 0.33f);
      limitGreenForMatrix = float2(0.3f, 0.6f);
      limitBlueForMatrix  = float2(0.15f, 0.06f);
    }
    else if (primariesLimit == 3)
    {
      limitRedForMatrix   = float2(0.708f, 0.292f);
      limitGreenForMatrix = float2(0.170f, 0.797f);
      limitBlueForMatrix  = float2(0.131f, 0.046f);
    }
    else if (primariesLimit == 4)
    {
      limitRedForMatrix   = float2(0.680f, 0.320f);
      limitGreenForMatrix = float2(0.265f, 0.690f);
      limitBlueForMatrix  = float2(0.150f, 0.060f);
    }
    else
    {
      limitRedForMatrix   = float2(1.0f, 0.0f);
      limitGreenForMatrix = float2(0.0f, 1.0f);
      limitBlueForMatrix  = float2(0.0f, 0.0f);
    }

    RGB_to_XYZ_limit = RGBPrimsToXYZMatrix(limitRedForMatrix, limitGreenForMatrix, limitBlueForMatrix, limitWhiteForMatrix, 1.0f, 0);
    XYZ_to_RGB_limit = RGB_to_XYZ_limit.invert();

    RGB_to_XYZ_reach = generate_RGB_to_XYZ_matrix(primariesReach);
    XYZ_to_RGB_reach = RGB_to_XYZ_reach.invert();

    RGB_to_XYZ_output = generate_RGB_to_XYZ_matrix(primariesOut);
    XYZ_to_RGB_output = RGB_to_XYZ_output.invert();

    float3 white(1.0f, 1.0f, 1.0f);
    inWhite    = vector_dot(RGB_to_XYZ_input, white);
    outWhite   = vector_dot(RGB_to_XYZ_output, white);
    refWhite   = vector_dot(RGB_to_XYZ_limit, white);
    limitWhite = vector_dot(RGB_to_XYZ_limit, white); // TODO; could ref and limit be different?

    if (catDataSelection == 0)
    {
      CAT_CAT16.setArray(CAT_CAT16_data);
    }
    else if (catDataSelection == 1)
    {
      CAT_CAT16.setArray(Modified_CAT16_data);
    }
    else if (catDataSelection == 2)
    {
      CAT_CAT16 = RGBPrimsToXYZMatrix(rxy, gxy, bxy, wxy, 1.0f, 1);
    }
    CAT_CAT16_INVERSE = CAT_CAT16.invert();

    achromatic_weights = float3(ra, 1.0f, ba);
    a_weights   = float3(11.0f, -12.0f, 1.0f) / 11.0f;
    b_weights   = float3(1.0f, 1.0f, -2.0f) / 9.0f;
    generate_panlrcm();

    precompute_hellwig(inWhite, viewingConditions, L_A, Y_b, discountIlluminant_in, 0);
    precompute_hellwig(refWhite, outputViewingConditions, L_A, Y_b, discountIlluminant_mid, 1);
    precompute_hellwig(limitWhite, outputViewingConditions, L_A_out, Y_b_out, discountIlluminant_out, 2);
    initialise_non_linearities();

    // calculate the maximum expected J & M values for the given limit gamut
    // these are used as limiting values for the gamut boundary searches
    // limitJmax (assumed to match limitRGB white)
    limitJmax = RGB_to_JMh(float3(1.0f), RGB_to_XYZ_limit).x;

    // Cusp table for chroma compression gamut
    float3x3 RGB_to_XYZ_cgReach;
    if (ccReach == 0) // Chroma Compression Space (primaries defined in kernel params)
    {
      RGB_to_XYZ_cgReach = RGBPrimsToXYZMatrix(crxy, cgxy, cbxy, cwxy, 1.0f, 0);
    }
    else if (ccReach == 1)
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(0);
    }
    else if (ccReach == 2)
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(1);
    }
    else
    {
      RGB_to_XYZ_cgReach = generate_RGB_to_XYZ_matrix(3);
    }
    const float3x3 XYZ_to_RGB_cgReach = RGB_to_XYZ_cgReach.invert();

    initialise_cusp_table(cgamutCuspTable, gamutCuspTableSize, RGB_to_XYZ_cgReach);
    initialise_reach_cusp_table(cgamutReachTable, gamutCuspTableSize, limitJmax, XYZ_to_RGB_cgReach);

    // With gamut mapper reach mode 7, use the chroma compression reach space with the
    // gamut mapper.
    if (primariesReach == 7) // TODO: always use same tables
      XYZ_to_RGB_reach = XYZ_to_RGB_cgReach;

    // Cusp table for limiting gamut
    initialise_cusp_table(gamutCuspTable, gamutCuspTableSize, RGB_to_XYZ_limit);
    initialise_reach_cusp_table(gamutCuspTableReach, gamutCuspTableSize, limitJmax, XYZ_to_RGB_reach);

    midJ = XYZ_to_JMh(refWhite * daniele_c_t * mmScaleFactor, outputViewingConditions, HK_mode_mid, 1).x;

    initialise_upper_hull_gamma();
    initialise_lower_hull_gamma();

    initialise_cusp_table(gamutCuspTableAP1, gamutCuspTableSize, AP1_to_XYZ);

    fitWhiteScale = 1.0f;
    if (fitWhite)
    {
      // Scale to fit maximum creative white channel value
      float3 creativeWhiteXYZ = vector_dot(RGB_to_XYZ_limit, float3(1.0f, 1.0f, 1.0f));
      float3 creativeWhiteRGB = vector_dot(XYZ_to_RGB_output, creativeWhiteXYZ);
      fitWhiteScale = 1.0f / max(creativeWhiteRGB.x, max(creativeWhiteRGB.y, creativeWhiteRGB.z));
    }
  }

  inline float compute_base_exponential_nonlinearity(float Y_backgrounf, float Y_white)
  {
    return 1.48f + sqrt(Y_backgrounf / Y_white);
  }

  void precompute_hellwig(float3 referenceWhite, int viewingConditions, float _L_A, float Y_b, bool discountIlluminant, int stage)
  {
    const float3 surround = viewingConditionsToSurround(viewingConditions);

    const float3 XYZ_w_scaled = referenceWhite * XYZ_w_scaler;

    // # Step 0
    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
    const float3 RGB_w = vector_dot(CAT_CAT16, XYZ_w_scaled);

    // # Computing degree of adaptation :math:`D`.
    if (!discountIlluminant)
    {
      float D = clamp(degree_of_adaptation(surround.x, _L_A), 0, 1);
      D_RGB[stage] = D * XYZ_w_scaled.y / RGB_w + 1 - D;
    }
    else
    {
      D_RGB[stage] = XYZ_w_scaled.y / RGB_w;
    }

    const float k  = 1.0f / (5.0f * _L_A + 1.0f);
    const float k4 = k * k * k * k;
    F_L[stage] = 0.2f * k4 * (5.0f * _L_A) + 0.1f * pow((1.0f - k4), 2.0f) * pow(5.0f * _L_A, 1.0f / 3.0f);

    z[stage] = compute_base_exponential_nonlinearity(Y_b, XYZ_w_scaled.y);

    // # Computing achromatic responses for the whitepoint.
    const float3 RGB_wc = D_RGB[stage] * RGB_w;
    const float3 RGB_aw = post_adaptation_non_linear_response_compression_forward(RGB_wc, stage);
    A_w[stage] = dot(achromatic_weights, RGB_aw);
  }

  void initialise_non_linearity(int stage)
  {
     nl_Fl_scaled[stage] = F_L[stage] * nl_normalise;
     nl_derivative_scale[stage] = nl_d_scale * nl_Fl_scaled[stage];

    // Break point calculations
     nl_fql[stage] = post_adaptation_non_linear_response_compression_forward_wheatley_f(ql, stage);
     nl_fqu[stage] = post_adaptation_non_linear_response_compression_forward_wheatley_f(qu, stage);
     nl_lower_slope[stage] = nl_fql[stage] / ql;
     nl_upper_slope[stage] = post_adaptation_non_linear_response_compression_forward_derivative_wheatley(qu, stage);
     const float ql_derivative = post_adaptation_non_linear_response_compression_forward_derivative_wheatley(ql, stage);

     // precompute lower Quadratic parameters
     nl_a2[stage] = (ql * ql_derivative - nl_fql[stage]) / (ql * ql);
     nl_a1[stage] = ql_derivative - 2 * ql * nl_a2[stage];
     nl_a0[stage] = 0.0; // TODO for now pass through origin
     nl_b_[stage] = nl_a1[stage] / nl_a2[stage];
     nl_average_roots[stage] = -nl_b_[stage] / 2;
  }

  void initialise_non_linearities()
  {
    nl_gamma = 0.42f;
    nl_normalise = 100.0f;
    nl_scale = 400.0f;
    nl_offset = 27.13f;
    nl_d_scale = nl_gamma * nl_scale * nl_offset;

    for (int i = 0; i < 3; ++i)
    {
      initialise_non_linearity(i);
    }
  }

  void initialise_cusp_table(float3 *output_table, const int table_size, const float3x3& matrix)
  {
    // the 'tempTableUnsorted' table is populated
    // in increments of H of the limiting gamut HSV space starting at H=0.0
    // since it is unlikely that HSV.H=0 and JMh.h=0 line up
    // the entries are then wrap-around shifted
    // so that the 'gamutCuspTable' starts with the lowest JMh.h value
    float3 tempTableUnsorted[360];
    int minhIndex = 0;
    for (int i = 0; i < table_size; ++i)
    {
      const float  hNorm   = float(i) / (table_size);
      const float3 RGB     = HSV_to_RGB(float3(hNorm, 1.0f, 1.0f));
      tempTableUnsorted[i] = RGB_to_JMh(RGB, matrix);
      if (tempTableUnsorted[i].z < tempTableUnsorted[minhIndex].z)
      {
        minhIndex = i;
      }
    }
    copy_table_rotated(tempTableUnsorted, table_size, output_table, minhIndex);
  }

  void copy_table_rotated(float3 *tableUnsorted, const int tableSize, float3 output_table[], const int offsetIndex)
  {
    for (int i = 0; i < tableSize; ++i)
    {
      output_table[i] = tableUnsorted[(offsetIndex + i) % tableSize];
    }
  }

  void initialise_reach_cusp_table(float3 *output_table, const int table_size, const float limitJ, const float3x3& matrix)
  {
    const float search_range = 100.0;
    for (int i = 0; i < table_size; ++i)
    {
      const float hue = base_hue_for_position(i, table_size);

      float low     = 0.0;
      float high    = low + search_range;
      bool  outside = false;

      while (!outside && high < 1400.0)
      {
        outside = any_below_zero(JMh_to_RGB(float3(limitJ, high, hue), matrix));
        if (!outside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      while ((high - low) > 1e-2)
      {
        const float sampleM = (high + low) / 2.0;
        outside             = any_below_zero(JMh_to_RGB(float3(limitJ, sampleM, hue), matrix));
        if (outside)
        {
          high = sampleM;
        }
        else
        {
          low = sampleM;
        }
      }
      output_table[i].x = limitJ;
      output_table[i].y = high;
      output_table[i].z = hue;
    }
  }

  inline bool outside_hull(const float3 newLimitRGB)
  {
    // limit value, once we cross this value, we are outside of the top gamut shell
    const float maxRGBtestVal = 1.0f;
    if (newLimitRGB.x > maxRGBtestVal || newLimitRGB.y > maxRGBtestVal || newLimitRGB.z > maxRGBtestVal)
    {
      return true;
    }
    return false;
  }

  bool evaluate_upper_hull_gamma_fit(const float2 JMcusp, float3 testJmh[], const int test_count, const float topGamma)
  {
    const float focusJ = lerp(JMcusp.x, midJ, min(1.0, cuspMidBlend - (JMcusp.x / limitJmax)));
    for (int testIndex = 0; testIndex < test_count; ++testIndex)
    {
      const float  slope_gain  = limitJmax * focusDist * getFocusGain(testJmh[testIndex].x, JMcusp.x);
      const float2 estimated_hull_gammas = float2(topGamma, lowerHullGamma);

      const float3 approxLimit =
        findGamutBoundaryIntersection(testJmh[testIndex], JMcusp, focusJ, limitJmax, slope_gain, smoothCusps, estimated_hull_gammas);
      const float3 approximate_JMh = float3(approxLimit.x, approxLimit.y, testJmh[testIndex].z);
      const float3 newLimitRGB     = JMh_to_RGB(approximate_JMh, XYZ_to_RGB_limit);

      if (!outside_hull(newLimitRGB))
      {
        return false;
      }
    }
    return true;
  }

  void initialise_upper_hull_gamma()
  {
    // Find upper hull gamma values for the gamut mapper
    // start by taking a h angle
    // get the cusp J value for that angle
    // find a J value halfway to the Jmax
    // iterate through gamma values until the approximate max M is negative through the actual boundary

    // positions between the cusp and Jmax we will check
    // variables that get set as we iterate through, once all are set to true we break the loop
    const int   test_count                = 3;
    const float testPositions[test_count] = {0.01f, 0.5f, 0.99f};
    for (int i = 0; i < gamutCuspTableSize; ++i)
    {
      const float hue = base_hue_for_position(i, gamutCuspTableSize);
      //  default value. This will get overridden as we loop, but can be a good diagnostic to make sure things are working
      gamutTopGamma[i]    = -1.0f;
      const float2 JMcusp = cuspFromTable(hue);
      float3       testJmh[test_count];
      for (int testIndex = 0; testIndex < test_count; ++testIndex)
      {
        // create test values halfway between the cusp and the Jmax
        testJmh[testIndex] = float3(JMcusp.x + ((limitJmax - JMcusp.x) * testPositions[testIndex]), JMcusp.y, hue);
      }

      const float search_range = 0.4;
      float       low          = 0.4;
      float       high         = low + search_range;
      bool        all_inside   = false;

      while (!all_inside && high < 5.0)
      {
        all_inside = evaluate_upper_hull_gamma_fit(JMcusp, testJmh, test_count, high);
        if (!all_inside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      float testGamma = -1.0;
      while ((high - low) > 1e-5)
      {
        testGamma  = (high + low) / 2.0;
        all_inside = evaluate_upper_hull_gamma_fit(JMcusp, testJmh, test_count, testGamma);
        if (all_inside)
        {
          high = testGamma;
        }
        else
        {
          low = testGamma;
        }
      }
      gamutTopGamma[i] = testGamma;
    }
  }

  inline bool any_below_zero(const float3 newLimitRGB)
  {
    if (newLimitRGB.x < 0.0f || newLimitRGB.y < 0.0f || newLimitRGB.z < 0.0f)
    {
      return true;
    }
    return false;
  }

  bool evaluate_lower_hull_gamma_fit(const float2 JMcusp, float3 testJmh[], const int test_count, const float bottomGamma)
  {
    const float focusJ = lerp(JMcusp.x, midJ, cuspMidBlend);
    for (int testIndex = 0; testIndex < test_count; ++testIndex)
    {
      const float slope_gain = limitJmax * focusDist * getFocusGain(testJmh[testIndex].x, JMcusp.x);
      const float2 estimated_hull_gammas = float2(upperHullGamma, bottomGamma);

      const float3 approxLimit     = findGamutBoundaryIntersection(testJmh[testIndex], JMcusp, focusJ, limitJmax,
                                                                   slope_gain, smoothCusps, estimated_hull_gammas);
      const float3 approximate_JMh = float3(approxLimit.x, approxLimit.y, testJmh[testIndex].z);
      const float3 newLimitRGB     = JMh_to_RGB(approximate_JMh, XYZ_to_RGB_limit);

      if (!any_below_zero(newLimitRGB))
      {
        return false;
      }
    }
    return true;
  }

  void initialise_lower_hull_gamma()
  {
    // Same process, for the bottom hull gamma
    const int   test_count                = 3;
    const float testPositions[test_count] = {0.01f, 0.4f, 0.75f};

    for (int i = 0; i < gamutCuspTableSize; ++i)
    {
      const float hue = base_hue_for_position(i, gamutCuspTableSize);

      gamutBottomGamma[i] = -1.0f;
      const float2 JMcusp = cuspFromTable(hue);
      float3       testJmh[test_count];
      for (int testIndex = 0; testIndex < test_count; ++testIndex)
      {
        testJmh[testIndex] = float3(JMcusp.x * testPositions[testIndex], JMcusp.y, hue);
      }

      const float search_range = 0.4;
      float       low          = 0.8;
      float       high         = low + search_range;
      bool        all_inside   = false;

      while (!all_inside && high < 5.0)
      {
        all_inside = evaluate_lower_hull_gamma_fit(JMcusp, testJmh, test_count, high);
        if (!all_inside)
        {
          low  = high;
          high = high + search_range;
        }
      }

      float testGamma = -1.0;
      while ((high - low) > 1e-5)
      {
        testGamma  = (high + low) / 2.0;
        all_inside = evaluate_lower_hull_gamma_fit(JMcusp, testJmh, test_count, testGamma);
        if (all_inside)
        {
          high = testGamma;
        }
        else
        {
          low = testGamma;
        }
      }
      gamutBottomGamma[i] = testGamma;
    }
  }

  void process()
  {
    SampleType(src) source = src();
    float3 srcRGB(source.x, source.y, source.z);
    float3 dstRGB;
    float3 compressedJMh;
    float3 tonemappedJMh;
    float3 JMh;
    float3 diagnostic;

    if (invert)
    {
      compressedJMh = output_RGB_to_JMh(srcRGB);
      tonemappedJMh = compressGamut(compressedJMh, 1);
      JMh           = inverseTonescale(tonemappedJMh, 2);
      diagnostic    = JMh_to_input_RGB(JMh);
    }
    else
    {
      JMh           = input_RGB_to_JMh(srcRGB);
      tonemappedJMh = forwardTonescale(JMh, 0);
      compressedJMh = compressGamut(tonemappedJMh, 0);
      diagnostic    = JMh_to_output_RGB(compressedJMh);
    }

    if (diagnosticMode == 1 || diagnosticMode == 6)
    {
      // Mode 6 actually returns XYZ, mode 1 returns real JMh
      if (invert)
      {
        diagnostic = JMh_to_input_RGB(srcRGB);
      }
      else
      {
        diagnostic = JMh;
      }
    }
    else if (diagnosticMode == 2 || diagnosticMode == 99)
    {
      diagnostic = tonemappedJMh;
    }
    else if (diagnosticMode == 3 || diagnosticMode == 5)
    {
      diagnostic = compressedJMh;
    }
    else if (diagnosticMode == 4 || diagnosticMode == 7)
    {
      if (diagnosticMode == 4)
        srcRGB = JMh;
      dstRGB     = JMh_to_output_RGB(srcRGB);
      diagnostic = dstRGB;
    }
    else if (diagnosticMode == 8)
    {
      diagnostic = inWhite;
    }
    else if (diagnosticMode == 9)
    {
      diagnostic = outWhite;
    }
    else if (diagnosticMode == 10)
    {
      diagnostic = limitWhite;
    }
    else if (diagnosticMode == 12)
    {
      // output gamut boundary
      diagnostic = compressGamut(srcRGB, 1);
    }
    else if (diagnosticMode == 13)
    {
      // output gamut boundary
      diagnostic = compressGamut(srcRGB, invert);
    }
    else if (diagnosticMode == 14)
    {
      // output gamut cusp
      const float2 JMcusp = cuspFromTable(srcRGB.z);
      diagnostic          = float3(JMcusp.x, JMcusp.y, srcRGB.z);
    }
    else if (diagnosticMode == 15)
    {
      // output AP1 cusp
      const float2 JMcusp = cuspFromTableAP1(srcRGB.z);
      diagnostic          = float3(JMcusp.x, JMcusp.y, srcRGB.z);
    }
    else if (diagnosticMode == 18)
    {
      // output gamut boundary
      diagnostic = compressGamut(srcRGB, 0);
    }
    else if (diagnosticMode == 19)
    {
      // output Reach boundary
      diagnostic = getReachBoundry(srcRGB);
    }
    else if (diagnosticMode == 20)
    {
      // output JMFocus
      diagnostic = compressGamut(srcRGB, 1);
    }
    else if (diagnosticMode == 21)
    {
      // output JMFocus
      diagnostic = float3(hueDependantUpperHullGamma(srcRGB.z), 0.0f, 0.0f);
    }
    else if (diagnosticMode == 22)
    {
      float2 JMcusp = cuspFromTable(srcRGB.z);
      // create test value halfway between the cusp and the Jmax
      float slope_gain = limitJmax * focusDist;
      diagnostic       = float3(JMcusp.x + ((limitJmax - JMcusp.x) / 2.0f), JMcusp.y, srcRGB.z);
    }
    else if (diagnosticMode == 23)
    {
      float2 JMcusp = cuspFromTable(srcRGB.z);
      // create test value halfway between the cusp and the Jmax
      float  slope_gain  = limitJmax * focusDist;
      float3 testJmh     = float3(JMcusp.x + ((limitJmax - JMcusp.x) / 2.0f), JMcusp.y, srcRGB.z);
      const float2 estimated_hull_gammas = float2(hueDependantUpperHullGamma(JMh.z), hueDependantLowerHullGamma(JMh.z));

      float3 approxLimit = findGamutBoundaryIntersection(testJmh, JMcusp, (JMcusp.x + 38.0f) / 2, limitJmax, slope_gain, smoothCusps,
                                                         estimated_hull_gammas);
      diagnostic         = float3(approxLimit.x, approxLimit.y, srcRGB.z);
    }

    else if (diagnosticMode == 24)
    {
      float2 JMcusp = cuspFromTable(srcRGB.z);
      // create test value halfway between the cusp and the Jmax
      float  slope_gain  = limitJmax * focusDist;
      float3 testJmh     = float3(JMcusp.x + ((limitJmax - JMcusp.x) / 2.0f), JMcusp.y, srcRGB.z);
      const float2 estimated_hull_gammas = float2(hueDependantUpperHullGamma(JMh.z), hueDependantLowerHullGamma(JMh.z));
      float3 approxLimit = findGamutBoundaryIntersection(testJmh, JMcusp, (JMcusp.x + 38.0f) / 2, limitJmax, slope_gain, smoothCusps,
                                                         estimated_hull_gammas);
      float3 newLimitRGB = JMh_to_RGB(float3(approxLimit.x, approxLimit.y, srcRGB.z), XYZ_to_RGB_limit);
      diagnostic         = newLimitRGB;
    }

    else if (diagnosticMode == 25)
    {
      float2 JMcusp            = cuspFromTable(srcRGB.z);
      float  focusJ            = lerp(JMcusp.x, midJ, min(1.0f, cuspMidBlend - (JMcusp.x / limitJmax)));
      float  slope_gain        = limitJmax * focusDist * getFocusGain(JMh.x, JMcusp.x);
      const float2 estimated_hull_gammas = float2(hueDependantUpperHullGamma(JMh.z), hueDependantLowerHullGamma(JMh.z));

      float3 nickBoundryReturn = findGamutBoundaryIntersection(srcRGB, JMcusp, focusJ, limitJmax, slope_gain, smoothCusps,
                                                               estimated_hull_gammas);
      diagnostic               = float3(srcRGB.x, nickBoundryReturn.y, srcRGB.z);
    }
    else if (diagnosticMode == 26)
    {
      // XYZ back to luminance RGB
      float3 JMh = JMh_to_XYZ(srcRGB, outputViewingConditions, HK_mode_out, 2);
      diagnostic = vector_dot(XYZ_to_RGB_limit, JMh);
    }
    else if (diagnosticMode == 27)
    {
      // output
      diagnostic = float3(hueDependantLowerHullGamma(srcRGB.z), 0.0f, 0.0f);
    }
    else if (diagnosticMode == 28)
    {
      // output
      float2 JMcusp = cuspFromTable(srcRGB.z);
      const float2 estimated_hull_gammas = float2(hueDependantUpperHullGamma(JMh.z), hueDependantLowerHullGamma(JMh.z));

      diagnostic    = findGamutBoundaryIntersection(srcRGB, JMcusp, lerp(JMcusp.x, midJ, cuspMidBlend), limitJmax, 10000.0f, 0.0f,
                                                    estimated_hull_gammas);
    }

    // extra modes to allow for easier breakout of the order of events.
    // modes starting with 100

    ////// FORWARD PATHWAY

    else if (diagnosticMode == 100)
    {
      // display encoding to display linear
      diagnostic      = encodingToLuminance3(encodingIn, srcRGB);
    }
    else if (diagnosticMode == 101)
    {
      // convert to linear XYZ luminance values
      diagnostic = vector_dot(RGB_to_XYZ_input, srcRGB);
    }
    else if (diagnosticMode == 102)
    {
      // convert luminanceXYZ to JMh
      diagnostic = XYZ_to_JMh(srcRGB, viewingConditions, HK_mode_in, 0);
    }
    else if (diagnosticMode == 103)
    {
      // JMh to tonemappedJMh
      diagnostic = forwardTonescale(srcRGB, 0);
    }
    else if (diagnosticMode == 104)
    {
      // JMh to gamut compressed JMh
      diagnostic = compressGamut(srcRGB, 0);
    }
    else if (diagnosticMode == 105)
    {
      // JMh to luminance XYZ
      diagnostic = JMh_to_XYZ(srcRGB, outputViewingConditions, HK_mode_out, 2);
    }
    else if (diagnosticMode == 106)
    {
      // display luminance XYZ to display linear RGB
      diagnostic = vector_dot(XYZ_to_RGB_output, srcRGB);
    }
    else if (diagnosticMode == 107)
    {
      // display linear RGB to display encoded RGB
      diagnostic = luminanceToEncoding3(encodingOut, srcRGB);
    }

    ////// INVERSE PATHWAY

    else if (diagnosticMode == 200)
    {
      // output display encoded RGB to display linear RGB
      diagnostic = encodingToLuminance3(encodingOut, srcRGB);
    }
    else if (diagnosticMode == 201)
    {
      // output display linear RGB to output display linear XYZ
      diagnostic = vector_dot(RGB_to_XYZ_output, srcRGB);
    }
    else if (diagnosticMode == 202)
    {
      // output XYZ to JMh
      diagnostic = XYZ_to_JMh(srcRGB, viewingConditions, HK_mode_out, 2);
    }
    else if (diagnosticMode == 203)
    {
      // uncompress gamut
      diagnostic = compressGamut(srcRGB, 1);
    }
    else if (diagnosticMode == 204)
    {
      // inverse tonescale in JMh
      diagnostic = inverseTonescale(srcRGB, 0);
    }
    else if (diagnosticMode == 205)
    {
      // inverted JMh back to XYZ
      diagnostic = JMh_to_XYZ(srcRGB, viewingConditions, HK_mode_in, 0);
    }
    else if (diagnosticMode == 206)
    {
      // XYZ back to luminance RGB
      diagnostic = vector_dot(XYZ_to_RGB_input, srcRGB);
    }
    else if (diagnosticMode == 207)
    {
      // luminance RGB to input encoding RGB
      diagnostic = luminanceToEncoding3(encodingIn, srcRGB);
    }
    else if (diagnosticMode == 300)
    {
      diagnostic = post_adaptation_non_linear_response_compression_forward(srcRGB, 0);
    }
    else if (diagnosticMode == 301)
    {
      diagnostic = post_adaptation_non_linear_response_compression_inverse(srcRGB, 0);
    }
    else if (diagnosticMode == 302)
    {
      diagnostic = float3(limitJmax, RGB_to_XYZ_limit[0][0], RGB_to_XYZ_limit[0][1]);
    }

    dst() = float4(diagnostic.x, diagnostic.y, diagnostic.z, source.w);
  }
};
